[
  {
    "open_pages_titles": [
      "Projects ¬∑ Dashboard ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Projects ¬∑ Dashboard ¬∑ GitLab', focused, url='http://127.0.0.1:8023/'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[6] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[7] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[8] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[9] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[10] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[11] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Projects'\n\t\t[3] link 'New project', url='http://127.0.0.1:8023/projects/new'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Yours 14', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'Starred 3', url='http://127.0.0.1:8023/dashboard/projects/starred'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Explore', url='http://127.0.0.1:8023/explore'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Topics', url='http://127.0.0.1:8023/explore/projects/topics'\n\t\t[4] searchbox 'Filter by name'\n\t\t[5] button 'Name'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[18] link 'All', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[19] link 'Personal', url='http://127.0.0.1:8023/?personal=true&sort=name_asc'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[20] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\theading 'Byte Blaze / a11y-syntax-highlighting'\n\t\t\t\t\t[90] link 'Byte Blaze / a11y-syntax-highlighting', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üíÑ Accessible light and dark syntax highlighting themes'\n\t\t\t\t[21] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/starrers'\n\t\t\t\t[22] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/forks'\n\t\t\t\t[23] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/merge_requests'\n\t\t\t\t[24] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[25] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\theading 'Byte Blaze / a11y-webring.club'\n\t\t\t\t\t[91] link 'Byte Blaze / a11y-webring.club', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üåê A webring for digital accessibility practitioners.'\n\t\t\t\t[26] link '2', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/starrers'\n\t\t\t\t[27] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/forks'\n\t\t\t\t[28] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/merge_requests'\n\t\t\t\t[29] link '4', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[30] link 'A', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\theading 'The A11Y Project / a11yproject.com'\n\t\t\t\t\t[92] link 'The A11Y Project / a11yproject.com', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\tStaticText 'Maintainer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'The A11Y Project is a community-driven effort to make digital accessibility easier.'\n\t\t\t\t[31] link '21', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/starrers'\n\t\t\t\t[32] link '0', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/forks'\n\t\t\t\t[33] link '10', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/merge_requests'\n\t\t\t\t[34] link '40', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 2:15am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[35] link 'A', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\theading 'Byte Blaze / accessible-html-content-patterns'\n\t\t\t\t\t[93] link 'Byte Blaze / accessible-html-content-patterns', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText '‚ôø Ô∏è The full HTML5 Doctor Element Index as well as common markup patterns for quick reference.'\n\t\t\t\t[36] link '1', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/starrers'\n\t\t\t\t[37] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/forks'\n\t\t\t\t[38] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/merge_requests'\n\t\t\t\t[39] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[40] link '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/avatar?width=48'\n\t\t\t\theading 'Byte Blaze / cloud-to-butt'\n\t\t\t\t\t[94] link 'Byte Blaze / cloud-to-butt', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"Chrome extension that replaces occurrences of 'the cloud' with 'my butt'\"\n\t\t\t\t[41] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/starrers'\n\t\t\t\t[42] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/forks'\n\t\t\t\t[43] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/merge_requests'\n\t\t\t\t[44] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[45] link 'D', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\theading 'Primer / design'\n\t\t\t\t\t[95] link 'Primer / design', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\tStaticText 'Developer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Primer Design Guidelines'\n\t\t\t\t[46] link '21', url='http://127.0.0.1:8023/primer/design/-/starrers'\n\t\t\t\t[47] link '0', url='http://127.0.0.1:8023/primer/design/-/forks'\n\t\t\t\t[48] link '16', url='http://127.0.0.1:8023/primer/design/-/merge_requests'\n\t\t\t\t[49] link '21', url='http://127.0.0.1:8023/primer/design/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 3:04am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[50] link 'D', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\theading 'Byte Blaze / dotfiles'\n\t\t\t\t\t[96] link 'Byte Blaze / dotfiles', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'ü§ñ Computer setup'\n\t\t\t\t[51] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/starrers'\n\t\t\t\t[52] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/forks'\n\t\t\t\t[53] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/merge_requests'\n\t\t\t\t[54] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[55] link 'E', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\theading 'Byte Blaze / empathy-prompts'\n\t\t\t\t\t[97] link 'Byte Blaze / empathy-prompts', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üí° Ideas to help consider Inclusive Design principles when making things for others to use.'\n\t\t\t\t[56] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/starrers'\n\t\t\t\t[57] link '1', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/forks'\n\t\t\t\t[58] link '2', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/merge_requests'\n\t\t\t\t[59] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[60] link 'E', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\theading 'Byte Blaze / ericwbailey.website'\n\t\t\t\t\t[98] link 'Byte Blaze / ericwbailey.website', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üìê Repo for my personal website.'\n\t\t\t\t[61] link '2', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/starrers'\n\t\t\t\t[62] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/forks'\n\t\t\t\t[63] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/merge_requests'\n\t\t\t\t[64] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[65] link 'G', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\theading 'Byte Blaze / gimmiethat.space'\n\t\t\t\t\t[99] link 'Byte Blaze / gimmiethat.space', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'I need some space.'\n\t\t\t\t[66] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/starrers'\n\t\t\t\t[67] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/forks'\n\t\t\t\t[68] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/merge_requests'\n\t\t\t\t[69] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[70] link 'M', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\theading 'Byte Blaze / millennials-to-snake-people'\n\t\t\t\t\t[100] link 'Byte Blaze / millennials-to-snake-people', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"üêç Chrome extension that replaces occurrences of 'Millennials' with 'Snake People'\"\n\t\t\t\t[71] link '6', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/starrers'\n\t\t\t\t[72] link '0', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/forks'\n\t\t\t\t[73] link '2', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/merge_requests'\n\t\t\t\t[74] link '4', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[75] link 'R', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\theading 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\t\t[101] link 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"This extension can remove and restore the presence of timeline items generated by a project board event from GitHub's timeline.\"\n\t\t\t\t[76] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/starrers'\n\t\t\t\t[77] link '1', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/forks'\n\t\t\t\t[78] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/merge_requests'\n\t\t\t\t[79] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[80] link 'S', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\theading 'Byte Blaze / solarized-prism-theme'\n\t\t\t\t\t[102] link 'Byte Blaze / solarized-prism-theme', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'solarized theme for prism.js'\n\t\t\t\t[81] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/starrers'\n\t\t\t\t[82] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/forks'\n\t\t\t\t[83] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/merge_requests'\n\t\t\t\t[84] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:23am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[85] link 'T', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\theading 'Byte Blaze / timeit'\n\t\t\t\t\t[103] link 'Byte Blaze / timeit', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Rails implementation of time tracking tool timeit'\n\t\t\t\t[86] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/starrers'\n\t\t\t\t[87] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/forks'\n\t\t\t\t[88] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/merge_requests'\n\t\t\t\t[89] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'",
    "action": {
      "code": "fill('7', 'best GAN python implementation', True)",
      "thought": "We need to initiate a search to find the relevant project. The search field with ID `7` is the interactive element that will return search results for repositories. Executing a search will provide the repository page where the SSH clone URL can be extracted.",
      "type": "fill",
      "args": {
        "bid": "7",
        "value": "best GAN python implementation",
        "press_enter_after": true
      },
      "selected_element": {
        "nodeId": "295",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "textbox"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 170
        },
        "name": {
          "type": "computedString",
          "value": "Search GitLab",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "attribute": "aria-label"
            },
            {
              "type": "relatedElement",
              "nativeSource": "label"
            },
            {
              "type": "attribute",
              "attribute": "title"
            },
            {
              "type": "placeholder",
              "value": {
                "type": "computedString",
                "value": "Search GitLab"
              },
              "attribute": "placeholder",
              "attributeValue": {
                "type": "string",
                "value": "Search GitLab"
              }
            },
            {
              "type": "placeholder",
              "attribute": "aria-placeholder",
              "superseded": true
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "invalid",
            "value": {
              "type": "token",
              "value": "false"
            }
          },
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "editable",
            "value": {
              "type": "token",
              "value": "plaintext"
            }
          },
          {
            "name": "settable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "multiline",
            "value": {
              "type": "boolean",
              "value": false
            }
          },
          {
            "name": "readonly",
            "value": {
              "type": "boolean",
              "value": false
            }
          },
          {
            "name": "required",
            "value": {
              "type": "boolean",
              "value": false
            }
          }
        ],
        "parentId": "290",
        "childIds": [],
        "backendDOMNodeId": 295,
        "browsergym_id": "130",
        "weboperator_id": 7
      }
    },
    "action_error": "",
    "obs_description": "The dashboard page is currently displayed with a search textbox (ID `7`). No repository information is visible yet.  \nThis textbox is likely used to search projects across the GitLab instance, which is the logical step to locate a repository related to \"best GAN python implementation\".",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/",
        "header": {
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.root.477a3e47.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/dashboard_projects-f9a66f28504de91a1e7afb2a864211329c4999faea5eea95d4a5ea97ffd7bc6d.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/icons-ce4e8ebe16c824ec266af5c86cfa08b0d35e88b4fa857e862dd87bbc726986bc.svg",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/avatar?width=48",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-gfm_metrics-initInviteMembersModal-statusModalBundle-top_nav-wiki_edit.78c0213a.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "Projects ¬∑ Dashboard ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Projects ¬∑ Dashboard ¬∑ GitLab', focused, url='http://127.0.0.1:8023/'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[6] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\tsearch 'Search GitLab'\n\t\t\t\t\t[89] searchbox 'Search GitLab' value='best GAN python implementation', focused, describedby='search-input-description'\n\t\t\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t\t\t[90] button 'Clear'\n\t\t\t\t\tStaticText 'in all GitLab'\n\t\t\t\t\tregion ''\n\t\t\t\t\t\tStaticText 'Type for new suggestions to appear below.'\n\t\t\t\t\tregion '', live='polite', atomic, relevant='additions text'\n\t\t\t\t\t\tStaticText 'Results updated. 1 results available. Use the up and down arrow keys to navigate search results list, or ENTER to submit.'\n\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t[105] menuitem 'best GAN python implementation all GitLab'\n\t\t\t\t\t\t\tparagraph ''\n\t\t\t\t\t\t\t\tStaticText 'in all GitLab best GAN python implementation'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[7] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[8] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[9] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[10] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[11] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Projects'\n\t\t[3] link 'New project', url='http://127.0.0.1:8023/projects/new'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Yours 14', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Starred 3', url='http://127.0.0.1:8023/dashboard/projects/starred'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'Explore', url='http://127.0.0.1:8023/explore'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Topics', url='http://127.0.0.1:8023/explore/projects/topics'\n\t\t[4] searchbox 'Filter by name'\n\t\t[5] button 'Name'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'All', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[18] link 'Personal', url='http://127.0.0.1:8023/?personal=true&sort=name_asc'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[19] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\theading 'Byte Blaze / a11y-syntax-highlighting'\n\t\t\t\t\t[91] link 'Byte Blaze / a11y-syntax-highlighting', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üíÑ Accessible light and dark syntax highlighting themes'\n\t\t\t\t[20] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/starrers'\n\t\t\t\t[21] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/forks'\n\t\t\t\t[22] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/merge_requests'\n\t\t\t\t[23] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[24] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\theading 'Byte Blaze / a11y-webring.club'\n\t\t\t\t\t[92] link 'Byte Blaze / a11y-webring.club', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üåê A webring for digital accessibility practitioners.'\n\t\t\t\t[25] link '2', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/starrers'\n\t\t\t\t[26] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/forks'\n\t\t\t\t[27] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/merge_requests'\n\t\t\t\t[28] link '4', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[29] link 'A', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\theading 'The A11Y Project / a11yproject.com'\n\t\t\t\t\t[93] link 'The A11Y Project / a11yproject.com', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\tStaticText 'Maintainer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'The A11Y Project is a community-driven effort to make digital accessibility easier.'\n\t\t\t\t[30] link '21', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/starrers'\n\t\t\t\t[31] link '0', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/forks'\n\t\t\t\t[32] link '10', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/merge_requests'\n\t\t\t\t[33] link '40', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 2:15am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[34] link 'A', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\theading 'Byte Blaze / accessible-html-content-patterns'\n\t\t\t\t\t[94] link 'Byte Blaze / accessible-html-content-patterns', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText '‚ôø Ô∏è The full HTML5 Doctor Element Index as well as common markup patterns for quick reference.'\n\t\t\t\t[35] link '1', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/starrers'\n\t\t\t\t[36] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/forks'\n\t\t\t\t[37] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/merge_requests'\n\t\t\t\t[38] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[39] link '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/avatar?width=48'\n\t\t\t\theading 'Byte Blaze / cloud-to-butt'\n\t\t\t\t\t[95] link 'Byte Blaze / cloud-to-butt', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"Chrome extension that replaces occurrences of 'the cloud' with 'my butt'\"\n\t\t\t\t[40] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/starrers'\n\t\t\t\t[41] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/forks'\n\t\t\t\t[42] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/merge_requests'\n\t\t\t\t[43] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[44] link 'D', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\theading 'Primer / design'\n\t\t\t\t\t[96] link 'Primer / design', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\tStaticText 'Developer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Primer Design Guidelines'\n\t\t\t\t[45] link '21', url='http://127.0.0.1:8023/primer/design/-/starrers'\n\t\t\t\t[46] link '0', url='http://127.0.0.1:8023/primer/design/-/forks'\n\t\t\t\t[47] link '16', url='http://127.0.0.1:8023/primer/design/-/merge_requests'\n\t\t\t\t[48] link '21', url='http://127.0.0.1:8023/primer/design/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 3:04am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[49] link 'D', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\theading 'Byte Blaze / dotfiles'\n\t\t\t\t\t[97] link 'Byte Blaze / dotfiles', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'ü§ñ Computer setup'\n\t\t\t\t[50] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/starrers'\n\t\t\t\t[51] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/forks'\n\t\t\t\t[52] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/merge_requests'\n\t\t\t\t[53] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[54] link 'E', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\theading 'Byte Blaze / empathy-prompts'\n\t\t\t\t\t[98] link 'Byte Blaze / empathy-prompts', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üí° Ideas to help consider Inclusive Design principles when making things for others to use.'\n\t\t\t\t[55] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/starrers'\n\t\t\t\t[56] link '1', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/forks'\n\t\t\t\t[57] link '2', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/merge_requests'\n\t\t\t\t[58] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[59] link 'E', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\theading 'Byte Blaze / ericwbailey.website'\n\t\t\t\t\t[99] link 'Byte Blaze / ericwbailey.website', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üìê Repo for my personal website.'\n\t\t\t\t[60] link '2', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/starrers'\n\t\t\t\t[61] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/forks'\n\t\t\t\t[62] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/merge_requests'\n\t\t\t\t[63] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[64] link 'G', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\theading 'Byte Blaze / gimmiethat.space'\n\t\t\t\t\t[100] link 'Byte Blaze / gimmiethat.space', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'I need some space.'\n\t\t\t\t[65] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/starrers'\n\t\t\t\t[66] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/forks'\n\t\t\t\t[67] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/merge_requests'\n\t\t\t\t[68] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[69] link 'M', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\theading 'Byte Blaze / millennials-to-snake-people'\n\t\t\t\t\t[101] link 'Byte Blaze / millennials-to-snake-people', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"üêç Chrome extension that replaces occurrences of 'Millennials' with 'Snake People'\"\n\t\t\t\t[70] link '6', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/starrers'\n\t\t\t\t[71] link '0', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/forks'\n\t\t\t\t[72] link '2', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/merge_requests'\n\t\t\t\t[73] link '4', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[74] link 'R', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\theading 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\t\t[102] link 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"This extension can remove and restore the presence of timeline items generated by a project board event from GitHub's timeline.\"\n\t\t\t\t[75] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/starrers'\n\t\t\t\t[76] link '1', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/forks'\n\t\t\t\t[77] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/merge_requests'\n\t\t\t\t[78] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[79] link 'S', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\theading 'Byte Blaze / solarized-prism-theme'\n\t\t\t\t\t[103] link 'Byte Blaze / solarized-prism-theme', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'solarized theme for prism.js'\n\t\t\t\t[80] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/starrers'\n\t\t\t\t[81] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/forks'\n\t\t\t\t[82] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/merge_requests'\n\t\t\t\t[83] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:23am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[84] link 'T', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\theading 'Byte Blaze / timeit'\n\t\t\t\t\t[104] link 'Byte Blaze / timeit', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Rails implementation of time tracking tool timeit'\n\t\t\t\t[85] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/starrers'\n\t\t\t\t[86] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/forks'\n\t\t\t\t[87] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/merge_requests'\n\t\t\t\t[88] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'",
    "action": {
      "code": "click('105')",
      "thought": "The goal requires retrieving the SSH clone command of the best GAN Python implementation.  \nThe only potentially relevant project is the search result linked by ID 105.  \nClicking this item will navigate to that project‚Äôs page where the SSH URL can be read from the ‚ÄúClone‚Äù options.",
      "type": "click",
      "args": {
        "bid": "105"
      },
      "selected_element": {
        "nodeId": "2618",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "menuitem"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 124
        },
        "name": {
          "type": "computedString",
          "value": " best GAN python implementation all GitLab ",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "value": {
                "type": "computedString",
                "value": " best GAN python implementation all GitLab "
              },
              "attribute": "aria-label",
              "attributeValue": {
                "type": "string",
                "value": " best GAN python implementation all GitLab "
              }
            },
            {
              "type": "contents",
              "value": {
                "type": "computedString",
                "value": "in all GitLab best GAN python implementation"
              },
              "superseded": true
            },
            {
              "type": "attribute",
              "value": {
                "type": "computedString",
                "value": "in all GitLab"
              },
              "attribute": "title",
              "attributeValue": {
                "type": "string",
                "value": "in all GitLab"
              },
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          }
        ],
        "parentId": "2617",
        "childIds": [
          "2626"
        ],
        "backendDOMNodeId": 2618,
        "browsergym_id": "911",
        "weboperator_id": 105
      }
    },
    "action_error": "",
    "obs_description": "The search for ‚Äúbest GAN python implementation‚Äù returned a single suggestion.  \n- The list item contains a menuitem with ID **105** titled ‚Äúbest GAN python implementation all GitLab‚Äù.  \n- No project page is currently displayed; opening the suggestion is required to view the repository details and SSH clone URL.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/5.7e84824d.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/globalSearch.c68dedea.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "best GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'best GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='best GAN python implementation'\n\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 0', url='http://127.0.0.1:8023/search?scope=issues&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 1', url='http://127.0.0.1:8023/search?scope=merge_requests&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=best+GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching best GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'best GAN python implementation'",
    "action": {
      "type": "goto",
      "args": {
        "url": "http://127.0.0.1:8023/"
      },
      "code": "goto('http://127.0.0.1:8023/')",
      "thought": "Jump Action"
    },
    "action_error": "",
    "obs_description": null,
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
        "header": {
          "referer": "http://127.0.0.1:8023/",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "O2wWVuUulwIi262AZt4mIJCZBnuwwVDGQybTJa94enS0l/p+xhtmBSZai4bYe0C02qFcSJJZ8rKpiPL6QJkfvQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "O2wWVuUulwIi262AZt4mIJCZBnuwwVDGQybTJa94enS0l/p+xhtmBSZai4bYe0C02qFcSJJZ8rKpiPL6QJkfvQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "O2wWVuUulwIi262AZt4mIJCZBnuwwVDGQybTJa94enS0l/p+xhtmBSZai4bYe0C02qFcSJJZ8rKpiPL6QJkfvQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "O2wWVuUulwIi262AZt4mIJCZBnuwwVDGQybTJa94enS0l/p+xhtmBSZai4bYe0C02qFcSJJZ8rKpiPL6QJkfvQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "Projects ¬∑ Dashboard ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Projects ¬∑ Dashboard ¬∑ GitLab', focused, url='http://127.0.0.1:8023/'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[6] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[7] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[8] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[9] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[10] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[11] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Projects'\n\t\t[3] link 'New project', url='http://127.0.0.1:8023/projects/new'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Yours 14', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'Starred 3', url='http://127.0.0.1:8023/dashboard/projects/starred'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Explore', url='http://127.0.0.1:8023/explore'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Topics', url='http://127.0.0.1:8023/explore/projects/topics'\n\t\t[4] searchbox 'Filter by name'\n\t\t[5] button 'Name'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[18] link 'All', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[19] link 'Personal', url='http://127.0.0.1:8023/?personal=true&sort=name_asc'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[20] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\theading 'Byte Blaze / a11y-syntax-highlighting'\n\t\t\t\t\t[90] link 'Byte Blaze / a11y-syntax-highlighting', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üíÑ Accessible light and dark syntax highlighting themes'\n\t\t\t\t[21] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/starrers'\n\t\t\t\t[22] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/forks'\n\t\t\t\t[23] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/merge_requests'\n\t\t\t\t[24] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-syntax-highlighting/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[25] link 'A', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\theading 'Byte Blaze / a11y-webring.club'\n\t\t\t\t\t[91] link 'Byte Blaze / a11y-webring.club', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üåê A webring for digital accessibility practitioners.'\n\t\t\t\t[26] link '2', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/starrers'\n\t\t\t\t[27] link '0', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/forks'\n\t\t\t\t[28] link '1', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/merge_requests'\n\t\t\t\t[29] link '4', url='http://127.0.0.1:8023/byteblaze/a11y-webring.club/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[30] link 'A', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\theading 'The A11Y Project / a11yproject.com'\n\t\t\t\t\t[92] link 'The A11Y Project / a11yproject.com', url='http://127.0.0.1:8023/a11yproject/a11yproject.com'\n\t\t\t\tStaticText 'Maintainer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'The A11Y Project is a community-driven effort to make digital accessibility easier.'\n\t\t\t\t[31] link '21', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/starrers'\n\t\t\t\t[32] link '0', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/forks'\n\t\t\t\t[33] link '10', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/merge_requests'\n\t\t\t\t[34] link '40', url='http://127.0.0.1:8023/a11yproject/a11yproject.com/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 2:15am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[35] link 'A', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\theading 'Byte Blaze / accessible-html-content-patterns'\n\t\t\t\t\t[93] link 'Byte Blaze / accessible-html-content-patterns', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText '‚ôø Ô∏è The full HTML5 Doctor Element Index as well as common markup patterns for quick reference.'\n\t\t\t\t[36] link '1', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/starrers'\n\t\t\t\t[37] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/forks'\n\t\t\t\t[38] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/merge_requests'\n\t\t\t\t[39] link '0', url='http://127.0.0.1:8023/byteblaze/accessible-html-content-patterns/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[40] link '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/avatar?width=48'\n\t\t\t\theading 'Byte Blaze / cloud-to-butt'\n\t\t\t\t\t[94] link 'Byte Blaze / cloud-to-butt', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"Chrome extension that replaces occurrences of 'the cloud' with 'my butt'\"\n\t\t\t\t[41] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/starrers'\n\t\t\t\t[42] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/forks'\n\t\t\t\t[43] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/merge_requests'\n\t\t\t\t[44] link '0', url='http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[45] link 'D', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\theading 'Primer / design'\n\t\t\t\t\t[95] link 'Primer / design', url='http://127.0.0.1:8023/primer/design'\n\t\t\t\tStaticText 'Developer'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Primer Design Guidelines'\n\t\t\t\t[46] link '21', url='http://127.0.0.1:8023/primer/design/-/starrers'\n\t\t\t\t[47] link '0', url='http://127.0.0.1:8023/primer/design/-/forks'\n\t\t\t\t[48] link '16', url='http://127.0.0.1:8023/primer/design/-/merge_requests'\n\t\t\t\t[49] link '21', url='http://127.0.0.1:8023/primer/design/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 3:04am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[50] link 'D', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\theading 'Byte Blaze / dotfiles'\n\t\t\t\t\t[96] link 'Byte Blaze / dotfiles', url='http://127.0.0.1:8023/byteblaze/dotfiles'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'ü§ñ Computer setup'\n\t\t\t\t[51] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/starrers'\n\t\t\t\t[52] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/forks'\n\t\t\t\t[53] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/merge_requests'\n\t\t\t\t[54] link '0', url='http://127.0.0.1:8023/byteblaze/dotfiles/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[55] link 'E', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\theading 'Byte Blaze / empathy-prompts'\n\t\t\t\t\t[97] link 'Byte Blaze / empathy-prompts', url='http://127.0.0.1:8023/byteblaze/empathy-prompts'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üí° Ideas to help consider Inclusive Design principles when making things for others to use.'\n\t\t\t\t[56] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/starrers'\n\t\t\t\t[57] link '1', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/forks'\n\t\t\t\t[58] link '2', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/merge_requests'\n\t\t\t\t[59] link '6', url='http://127.0.0.1:8023/byteblaze/empathy-prompts/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[60] link 'E', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\theading 'Byte Blaze / ericwbailey.website'\n\t\t\t\t\t[98] link 'Byte Blaze / ericwbailey.website', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'üìê Repo for my personal website.'\n\t\t\t\t[61] link '2', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/starrers'\n\t\t\t\t[62] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/forks'\n\t\t\t\t[63] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/merge_requests'\n\t\t\t\t[64] link '0', url='http://127.0.0.1:8023/byteblaze/ericwbailey.website/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[65] link 'G', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\theading 'Byte Blaze / gimmiethat.space'\n\t\t\t\t\t[99] link 'Byte Blaze / gimmiethat.space', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'I need some space.'\n\t\t\t\t[66] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/starrers'\n\t\t\t\t[67] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/forks'\n\t\t\t\t[68] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/merge_requests'\n\t\t\t\t[69] link '0', url='http://127.0.0.1:8023/byteblaze/gimmiethat.space/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[70] link 'M', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\theading 'Byte Blaze / millennials-to-snake-people'\n\t\t\t\t\t[100] link 'Byte Blaze / millennials-to-snake-people', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"üêç Chrome extension that replaces occurrences of 'Millennials' with 'Snake People'\"\n\t\t\t\t[71] link '6', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/starrers'\n\t\t\t\t[72] link '0', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/forks'\n\t\t\t\t[73] link '2', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/merge_requests'\n\t\t\t\t[74] link '4', url='http://127.0.0.1:8023/byteblaze/millennials-to-snake-people/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[75] link 'R', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\theading 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\t\t[101] link 'Byte Blaze / remove-board-movement-events-from-the-github-issue-timeline', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"This extension can remove and restore the presence of timeline items generated by a project board event from GitHub's timeline.\"\n\t\t\t\t[76] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/starrers'\n\t\t\t\t[77] link '1', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/forks'\n\t\t\t\t[78] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/merge_requests'\n\t\t\t\t[79] link '0', url='http://127.0.0.1:8023/byteblaze/remove-board-movement-events-from-the-github-issue-timeline/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[80] link 'S', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\theading 'Byte Blaze / solarized-prism-theme'\n\t\t\t\t\t[102] link 'Byte Blaze / solarized-prism-theme', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'solarized theme for prism.js'\n\t\t\t\t[81] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/starrers'\n\t\t\t\t[82] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/forks'\n\t\t\t\t[83] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/merge_requests'\n\t\t\t\t[84] link '0', url='http://127.0.0.1:8023/byteblaze/solarized-prism-theme/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Apr 25, 2023 3:23am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[85] link 'T', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\theading 'Byte Blaze / timeit'\n\t\t\t\t\t[103] link 'Byte Blaze / timeit', url='http://127.0.0.1:8023/byteblaze/timeit'\n\t\t\t\tStaticText 'Owner'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'Rails implementation of time tracking tool timeit'\n\t\t\t\t[86] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/starrers'\n\t\t\t\t[87] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/forks'\n\t\t\t\t[88] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/merge_requests'\n\t\t\t\t[89] link '0', url='http://127.0.0.1:8023/byteblaze/timeit/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 28, 2023 5:22am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'",
    "action": {
      "code": "fill('4', 'GAN', True)",
      "thought": "Directly searching for ‚ÄúGAN‚Äù in the project list will filter the results to those relevant to the goal. Once the desired project appears, we can navigate to its page and retrieve the SSH clone URL. There is no other interactive element currently visible that provides the clone command, so the first step is to find the appropriate repository using the search field.",
      "type": "fill",
      "args": {
        "bid": "4",
        "value": "GAN",
        "press_enter_after": true
      },
      "selected_element": {
        "nodeId": "645",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "searchbox"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 153
        },
        "name": {
          "type": "computedString",
          "value": "Filter by name",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "attribute": "aria-label"
            },
            {
              "type": "relatedElement",
              "nativeSource": "label"
            },
            {
              "type": "attribute",
              "attribute": "title"
            },
            {
              "type": "placeholder",
              "value": {
                "type": "computedString",
                "value": "Filter by name"
              },
              "attribute": "placeholder",
              "attributeValue": {
                "type": "string",
                "value": "Filter by name"
              }
            },
            {
              "type": "placeholder",
              "attribute": "aria-placeholder",
              "superseded": true
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "invalid",
            "value": {
              "type": "token",
              "value": "false"
            }
          },
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "editable",
            "value": {
              "type": "token",
              "value": "plaintext"
            }
          },
          {
            "name": "settable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          }
        ],
        "parentId": "644",
        "childIds": [],
        "backendDOMNodeId": 645,
        "browsergym_id": "269",
        "weboperator_id": 4
      }
    },
    "action_error": "",
    "obs_description": "The current page is the Projects dashboard of the local GitLab instance. It lists a variety of user projects under the main view, filtered by their names and sorted alphabetically. The relevant UI components include:\n- A \"Filter by name\" search box (ID: **4**) used to narrow the displayed projects.\n- A list of project entries, each with an ID and link (e.g., ID 20 for *Byte Blaze / a11y-syntax-highlighting*).\n\nThe goal is to find an existing repository that implements a Generative Adversarial Network (GAN) in Python and display the SSH clone command. The repository name likely contains the substring \"GAN\". This can be efficiently located by using the ‚ÄúFilter by name‚Äù search box to narrow down projects containing ‚ÄúGAN‚Äù.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/",
        "header": {
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.root.477a3e47.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/dashboard_projects-f9a66f28504de91a1e7afb2a864211329c4999faea5eea95d4a5ea97ffd7bc6d.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/byteblaze/cloud-to-butt/-/avatar?width=48",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-gfm_metrics-initInviteMembersModal-statusModalBundle-top_nav-wiki_edit.78c0213a.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "Projects ¬∑ Dashboard ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/?name=GAN&sort=name_asc"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Projects ¬∑ Dashboard ¬∑ GitLab', focused, url='http://127.0.0.1:8023/?name=GAN&sort=name_asc'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/?name=GAN&sort=name_asc#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[6] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[7] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[8] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[9] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[10] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[11] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Projects'\n\t\t[3] link 'New project', url='http://127.0.0.1:8023/projects/new'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Yours 14', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'Starred 3', url='http://127.0.0.1:8023/dashboard/projects/starred'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Explore', url='http://127.0.0.1:8023/explore'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Topics', url='http://127.0.0.1:8023/explore/projects/topics'\n\t\t[4] searchbox 'Filter by name' value='GAN'\n\t\t\tStaticText 'GAN'\n\t\t[5] button 'Name'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[18] link 'All', url='http://127.0.0.1:8023/dashboard/projects'\n\t\t\tlistitem ''\n\t\t\t\t[19] link 'Personal', url='http://127.0.0.1:8023/?name=GAN&personal=true&sort=name_asc'\n\t\timage '', url='http://127.0.0.1:8023/assets/illustrations/profile-page/personal-project-aac6cb755aba81e5e53700e89c3fd5bc02540ab6fcb7ab17481e35dc5a661c28.svg'\n\t\theading \"This user doesn't have any personal projects\"",
    "action": {
      "type": "goto",
      "args": {
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
      },
      "code": "goto('http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar')",
      "thought": "Jump Action"
    },
    "action_error": "",
    "obs_description": null,
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/?sort=name_asc&name=GAN&sort=name_asc",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "BrR/viOKhSnYFpzfttUErcww+nYDatrPzLth7FSXtOiJT5OWAL90LtyXutkIcGI5hgigRSHyeLsmFUAzu3bRIQ==",
          "referer": "http://127.0.0.1:8023/",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/illustrations/profile-page/personal-project-aac6cb755aba81e5e53700e89c3fd5bc02540ab6fcb7ab17481e35dc5a661c28.svg",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?sort=name_asc&name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
        "header": {
          "referer": "http://127.0.0.1:8023/?sort=name_asc&name=GAN&sort=name_asc",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.root.477a3e47.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/dashboard_projects-f9a66f28504de91a1e7afb2a864211329c4999faea5eea95d4a5ea97ffd7bc6d.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/illustrations/profile-page/personal-project-aac6cb755aba81e5e53700e89c3fd5bc02540ab6fcb7ab17481e35dc5a661c28.svg",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-gfm_metrics-initInviteMembersModal-statusModalBundle-top_nav-wiki_edit.78c0213a.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/?name=GAN&sort=name_asc",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "best GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'best GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='best GAN python implementation'\n\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 0', url='http://127.0.0.1:8023/search?scope=issues&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 1', url='http://127.0.0.1:8023/search?scope=merge_requests&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=best+GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching best GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'best GAN python implementation'",
    "action": {
      "code": "fill('8', 'GAN python implementation', True)",
      "thought": "The target repository likely does not exist under the exact phrase ‚Äúbest GAN python implementation‚Äù. A narrower or slightly altered query may return results. Updating the query to a more general phrase such as ‚ÄúGAN python implementation‚Äù should reveal relevant projects where the SSH clone command can be extracted.",
      "type": "fill",
      "args": {
        "bid": "8",
        "value": "GAN python implementation",
        "press_enter_after": true
      },
      "selected_element": {
        "nodeId": "3238",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "searchbox"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 153
        },
        "name": {
          "type": "computedString",
          "value": "Search for projects, issues, etc.",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "value": {
                "type": "computedString",
                "value": "Search for projects, issues, etc."
              },
              "attribute": "aria-label",
              "attributeValue": {
                "type": "string",
                "value": "Search for projects, issues, etc."
              }
            },
            {
              "type": "relatedElement",
              "superseded": true,
              "nativeSource": "label"
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            },
            {
              "type": "placeholder",
              "value": {
                "type": "computedString",
                "value": "Search for projects, issues, etc."
              },
              "attribute": "placeholder",
              "attributeValue": {
                "type": "string",
                "value": "Search for projects, issues, etc."
              },
              "superseded": true
            },
            {
              "type": "placeholder",
              "attribute": "aria-placeholder",
              "superseded": true
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "value": {
          "type": "string",
          "value": "best GAN python implementation"
        },
        "properties": [
          {
            "name": "invalid",
            "value": {
              "type": "token",
              "value": "false"
            }
          },
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "editable",
            "value": {
              "type": "token",
              "value": "plaintext"
            }
          },
          {
            "name": "settable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          }
        ],
        "parentId": "3234",
        "childIds": [
          "3739"
        ],
        "backendDOMNodeId": 3238,
        "browsergym_id": "227",
        "weboperator_id": 8
      }
    },
    "action_error": "",
    "obs_description": "On the current search page (`/search?search=best%20GAN%20python%20implementation`) the interface indicates that no projects match the query \"best GAN python implementation\" (`Projects 0`). The search box with ID‚ÄØ`8` is available and allows input for a new search query.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
        "header": {
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "PLaNlpht0waCT+6fxtmV1J/qTZW05S5gQ/rz+7M3gfizTWG+u1giAYbOyJl4fPNA1dIXppZ9jBSpVNIkXNbkMQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "PLaNlpht0waCT+6fxtmV1J/qTZW05S5gQ/rz+7M3gfizTWG+u1giAYbOyJl4fPNA1dIXppZ9jBSpVNIkXNbkMQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "PLaNlpht0waCT+6fxtmV1J/qTZW05S5gQ/rz+7M3gfizTWG+u1giAYbOyJl4fPNA1dIXppZ9jBSpVNIkXNbkMQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "PLaNlpht0waCT+6fxtmV1J/qTZW05S5gQ/rz+7M3gfizTWG+u1giAYbOyJl4fPNA1dIXppZ9jBSpVNIkXNbkMQ==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='GAN python implementation'\n\t\t\t\tStaticText 'GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 4', url='http://127.0.0.1:8023/search?scope=issues&search=GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 10', url='http://127.0.0.1:8023/search?scope=merge_requests&search=GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'GAN python implementation'",
    "action": {
      "type": "goto",
      "args": {
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
      },
      "code": "goto('http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar')",
      "thought": "Jump Action"
    },
    "action_error": "",
    "obs_description": null,
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
        "header": {
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "gCU8dMD6pgOygNawW9VJ0BWnqQQk3VqwTSkZpmStt0YP3tBc489XBLYB8LblcC9EX5/zNwZF+MSnhzh5i0zSjw==",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "gCU8dMD6pgOygNawW9VJ0BWnqQQk3VqwTSkZpmStt0YP3tBc489XBLYB8LblcC9EX5/zNwZF+MSnhzh5i0zSjw==",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "gCU8dMD6pgOygNawW9VJ0BWnqQQk3VqwTSkZpmStt0YP3tBc489XBLYB8LblcC9EX5/zNwZF+MSnhzh5i0zSjw==",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "gCU8dMD6pgOygNawW9VJ0BWnqQQk3VqwTSkZpmStt0YP3tBc489XBLYB8LblcC9EX5/zNwZF+MSnhzh5i0zSjw==",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN+python+implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "best GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'best GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='best GAN python implementation'\n\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 0', url='http://127.0.0.1:8023/search?scope=issues&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 1', url='http://127.0.0.1:8023/search?scope=merge_requests&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=best+GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching best GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'best GAN python implementation'",
    "action": {
      "code": "click('18')",
      "thought": "The desired SSH clone URL is only present on the repository page. Since the search returned no projects, we need to explore the projects scope to confirm whether there's a relevant repository. If none exists, another approach would be required (e.g., broaden the search term). However, the immediate next step to achieve the goal is to click the ‚ÄúProjects 0‚Äù link to verify if any repositories appear.",
      "type": "click",
      "args": {
        "bid": "18"
      },
      "selected_element": {
        "nodeId": "3399",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "link"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 110
        },
        "name": {
          "type": "computedString",
          "value": "Projects 0",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "attribute": "aria-label"
            },
            {
              "type": "contents",
              "value": {
                "type": "computedString",
                "value": "Projects 0"
              }
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "url",
            "value": {
              "type": "string",
              "value": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation"
            }
          }
        ],
        "parentId": "3398",
        "childIds": [
          "3401",
          "3403"
        ],
        "backendDOMNodeId": 3399,
        "browsergym_id": "285",
        "weboperator_id": 18
      }
    },
    "action_error": "",
    "obs_description": "The current search page shows no projects matching the query ‚Äúbest GAN python implementation‚Äù (Projects 0). The search scope links list shows a ‚ÄúProjects 0‚Äù link (ID 18) that, if clicked, would present a projects list, though it currently indicates zero results.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
        "header": {
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "CLz4kmRFnDZvMkT/f2c2ouAnkE+vKJx/LhjhSNNBktOHRxS6R3BtMWuzYvnBwlA2qh/KfI2wPgvEtsCXPKD3Gg==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "CLz4kmRFnDZvMkT/f2c2ouAnkE+vKJx/LhjhSNNBktOHRxS6R3BtMWuzYvnBwlA2qh/KfI2wPgvEtsCXPKD3Gg==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "CLz4kmRFnDZvMkT/f2c2ouAnkE+vKJx/LhjhSNNBktOHRxS6R3BtMWuzYvnBwlA2qh/KfI2wPgvEtsCXPKD3Gg==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "CLz4kmRFnDZvMkT/f2c2ouAnkE+vKJx/LhjhSNNBktOHRxS6R3BtMWuzYvnBwlA2qh/KfI2wPgvEtsCXPKD3Gg==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "best GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'best GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='best GAN python implementation'\n\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 0', url='http://127.0.0.1:8023/search?scope=issues&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 1', url='http://127.0.0.1:8023/search?scope=merge_requests&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=best+GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching best GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'best GAN python implementation'",
    "action": {
      "type": "goto",
      "args": {
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
      },
      "code": "goto('http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar')",
      "thought": "Jump Action"
    },
    "action_error": "",
    "obs_description": null,
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
        "header": {
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "4EsKK5uZXMEjzBURadn6xy5ll95ZOAm322gLejicVSBvsOYDuKytxidNMxfXfJxTZF3N7Xugq8Mxxiql130w6Q==",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "4EsKK5uZXMEjzBURadn6xy5ll95ZOAm322gLejicVSBvsOYDuKytxidNMxfXfJxTZF3N7Xugq8Mxxiql130w6Q==",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "4EsKK5uZXMEjzBURadn6xy5ll95ZOAm322gLejicVSBvsOYDuKytxidNMxfXfJxTZF3N7Xugq8Mxxiql130w6Q==",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "4EsKK5uZXMEjzBURadn6xy5ll95ZOAm322gLejicVSBvsOYDuKytxidNMxfXfJxTZF3N7Xugq8Mxxiql130w6Q==",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "best GAN python implementation ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'best GAN python implementation ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='best GAN python implementation'\n\t\t\t\tStaticText 'best GAN python implementation'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[18] link 'Projects 0', url='http://127.0.0.1:8023/search?scope=projects&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[19] link 'Issues 0', url='http://127.0.0.1:8023/search?scope=issues&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[20] link 'Merge requests 1', url='http://127.0.0.1:8023/search?scope=merge_requests&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[21] link 'Milestones 0', url='http://127.0.0.1:8023/search?scope=milestones&search=best+GAN+python+implementation'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[22] link 'Users 0', url='http://127.0.0.1:8023/search?scope=users&search=best+GAN+python+implementation'\n\t\theading \"We couldn't find any projects matching best GAN python implementation\"\n\t\t\tcode ''\n\t\t\t\tStaticText 'best GAN python implementation'",
    "action": {
      "code": "fill('8', 'GAN', True)",
      "thought": "To locate a relevant GAN implementation repository, we should broaden the search to just ‚ÄúGAN‚Äù, which is more likely to return existing projects. The new query will display any available projects, from which we can identify the best Python implementation and retrieve its SSH URL.",
      "type": "fill",
      "args": {
        "bid": "8",
        "value": "GAN",
        "press_enter_after": true
      },
      "selected_element": {
        "nodeId": "3238",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "searchbox"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 153
        },
        "name": {
          "type": "computedString",
          "value": "Search for projects, issues, etc.",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "value": {
                "type": "computedString",
                "value": "Search for projects, issues, etc."
              },
              "attribute": "aria-label",
              "attributeValue": {
                "type": "string",
                "value": "Search for projects, issues, etc."
              }
            },
            {
              "type": "relatedElement",
              "superseded": true,
              "nativeSource": "label"
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            },
            {
              "type": "placeholder",
              "value": {
                "type": "computedString",
                "value": "Search for projects, issues, etc."
              },
              "attribute": "placeholder",
              "attributeValue": {
                "type": "string",
                "value": "Search for projects, issues, etc."
              },
              "superseded": true
            },
            {
              "type": "placeholder",
              "attribute": "aria-placeholder",
              "superseded": true
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "value": {
          "type": "string",
          "value": "best GAN python implementation"
        },
        "properties": [
          {
            "name": "invalid",
            "value": {
              "type": "token",
              "value": "false"
            }
          },
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "editable",
            "value": {
              "type": "token",
              "value": "plaintext"
            }
          },
          {
            "name": "settable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          }
        ],
        "parentId": "3234",
        "childIds": [
          "3739"
        ],
        "backendDOMNodeId": 3238,
        "browsergym_id": "227",
        "weboperator_id": 8
      }
    },
    "action_error": "",
    "obs_description": "The search results page currently shows no matching projects for the query ‚Äúbest GAN python implementation‚Äù. The search input box (ID‚ÄØ8) contains the previous query text. No repository page is open yet.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
        "header": {
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "OUfO39adnDR0LhOXZjk+5vd6owc2/6XFcwt3W5Amndq2vCL39ahtM3CvNZHYnFhyvUL5NBRnB7GZpVaEf8f4Ew==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "OUfO39adnDR0LhOXZjk+5vd6owc2/6XFcwt3W5Amndq2vCL39ahtM3CvNZHYnFhyvUL5NBRnB7GZpVaEf8f4Ew==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "OUfO39adnDR0LhOXZjk+5vd6owc2/6XFcwt3W5Amndq2vCL39ahtM3CvNZHYnFhyvUL5NBRnB7GZpVaEf8f4Ew==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=best+GAN+python+implementation",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "OUfO39adnDR0LhOXZjk+5vd6owc2/6XFcwt3W5Amndq2vCL39ahtM3CvNZHYnFhyvUL5NBRnB7GZpVaEf8f4Ew==",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "GAN ¬∑ Search ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'GAN ¬∑ Search ¬∑ GitLab', focused, url='http://127.0.0.1:8023/search?search=GAN&nav_source=navbar'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/search?search=GAN&nav_source=navbar#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[11] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[12] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[13] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[14] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[15] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[16] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[17] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tmain ''\n\t\theading 'Search'\n\t\t[3] LabelText ''\n\t\t\tStaticText 'What are you searching for?'\n\t\tgroup ''\n\t\t\t[8] searchbox 'Search for projects, issues, etc.' value='GAN'\n\t\t\t\tStaticText 'GAN'\n\t\t\t[9] button 'Clear'\n\t\t\t[10] button 'Search'\n\t\t[4] LabelText ''\n\t\t\tStaticText 'Group'\n\t\t[5] button 'Any', hasPopup='menu', expanded=False\n\t\t[6] LabelText ''\n\t\t\tStaticText 'Project'\n\t\t[7] button 'Any', hasPopup='menu', expanded=False\n\t\tseparator '', orientation='horizontal'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[28] link 'Projects 2', url='http://127.0.0.1:8023/search?scope=projects&search=GAN'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[29] link 'Issues 99 Result count is over limit.', url='http://127.0.0.1:8023/search?scope=issues&search=GAN'\n\t\t\t\t\t\timage 'Result count is over limit.'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[30] link 'Merge requests 99 Result count is over limit.', url='http://127.0.0.1:8023/search?scope=merge_requests&search=GAN'\n\t\t\t\t\t\timage 'Result count is over limit.'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[31] link 'Milestones 1', url='http://127.0.0.1:8023/search?scope=milestones&search=GAN'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[32] link 'Users 10', url='http://127.0.0.1:8023/search?scope=users&search=GAN'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[18] link 'P', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\t\t\t\theading 'Erik Linder-Nor√©n / PyTorch-GAN'\n\t\t\t\t\t[33] link 'Erik Linder-Nor√©n / PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText 'PyTorch implementations of Generative Adversarial Networks.'\n\t\t\t\t[19] link '45', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/starrers'\n\t\t\t\t[20] link '0', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks'\n\t\t\t\t[21] link '24', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/merge_requests'\n\t\t\t\t[22] link '102', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 20, 2023 6:12am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\t\tlistitem ''\n\t\t\t\t[23] link 'L', url='http://127.0.0.1:8023/learn-anything/learn-anything'\n\t\t\t\theading 'Learn Anything / learn-anything'\n\t\t\t\t\t[34] link 'Learn Anything / learn-anything', url='http://127.0.0.1:8023/learn-anything/learn-anything'\n\t\t\t\tparagraph ''\n\t\t\t\t\tStaticText \"Organize world's knowledge, explore connections and curate learning paths\"\n\t\t\t\t[24] link '0', url='http://127.0.0.1:8023/learn-anything/learn-anything/-/starrers'\n\t\t\t\t[25] link '0', url='http://127.0.0.1:8023/learn-anything/learn-anything/-/forks'\n\t\t\t\t[26] link '0', url='http://127.0.0.1:8023/learn-anything/learn-anything/-/merge_requests'\n\t\t\t\t[27] link '0', url='http://127.0.0.1:8023/learn-anything/learn-anything/-/issues'\n\t\t\t\tStaticText 'Updated'\n\t\t\t\ttime 'Mar 20, 2023 1:07am GMT+0600'\n\t\t\t\t\tStaticText '2 years ago'\n\t\tlist ''",
    "action": {
      "code": "click('18')",
      "thought": "To obtain the SSH clone command, we must view the repository‚Äôs project page where GitLab displays ‚ÄúClone with SSH‚Äù under the repository clone options. The current search results page does not provide the clone URL, so we need to navigate to the project page first.",
      "type": "click",
      "args": {
        "bid": "18"
      },
      "selected_element": {
        "nodeId": "13693",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "link"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 110
        },
        "name": {
          "type": "computedString",
          "value": "P",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "attribute": "aria-label"
            },
            {
              "type": "contents",
              "value": {
                "type": "computedString",
                "value": "P"
              }
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "url",
            "value": {
              "type": "string",
              "value": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN"
            }
          }
        ],
        "parentId": "13691",
        "childIds": [
          "13695"
        ],
        "backendDOMNodeId": 13693,
        "browsergym_id": "314",
        "weboperator_id": 18
      }
    },
    "action_error": "",
    "obs_description": "The search results list for ‚ÄúGAN‚Äù includes an entry for **Erik Linder‚ÄëNor√©n / PyTorch‚ÄëGAN** with a link (ID‚ÄØ18) that leads to the project page. This repository contains Python implementations of Generative Adversarial Networks and is likely the best Python GAN implementation available.",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
        "header": {
          "referer": "http://127.0.0.1:8023/search?search=best%20GAN%20python%20implementation&nav_source=navbar",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.admin.runners.index-pages.dashboard.issues-pages.groups.boards-pages.groups.crm.contac-e6b5cb1e.252c8d44.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-jira_connect_app-pages.admin.application_settings.general-pages.admin.clusters.show-pages.gr-fdfd1b3e.741589d4.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.search.show.d280b182.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/search-8de4d358e6b365c6eed626354561fef1da0e3061c093b44292ff27aa55fcd3be.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-ide_runtime-shortcutsBundle.55d8d9a7.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=issues&search=GAN",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "jYxQnzGdyTD4mHFRWueWwAdZnR27IUzEPEeN1hbi75wCd7y3Eqg4N/wZV1fkQvBUTWHHLpm57rDW6awJ+QOKVQ==",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=merge_requests&search=GAN",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "jYxQnzGdyTD4mHFRWueWwAdZnR27IUzEPEeN1hbi75wCd7y3Eqg4N/wZV1fkQvBUTWHHLpm57rDW6awJ+QOKVQ==",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=milestones&search=GAN",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "jYxQnzGdyTD4mHFRWueWwAdZnR27IUzEPEeN1hbi75wCd7y3Eqg4N/wZV1fkQvBUTWHHLpm57rDW6awJ+QOKVQ==",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/search/count?scope=users&search=GAN",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "jYxQnzGdyTD4mHFRWueWwAdZnR27IUzEPEeN1hbi75wCd7y3Eqg4N/wZV1fkQvBUTWHHLpm57rDW6awJ+QOKVQ==",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab', focused, url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[56] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[57] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[58] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[59] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[60] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[61] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[62] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[63] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tcomplementary 'Project navigation'\n\t\tlist ''\n\t\t\tlistitem 'PyTorch-GAN'\n\t\t\t\t[64] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\t\t\tlistitem ''\n\t\t\t\t[65] link 'Project information', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/activity'\n\t\t\tlistitem ''\n\t\t\t\t[66] link 'Repository', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master'\n\t\t\tlistitem ''\n\t\t\t\t[67] link 'Issues', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/issues'\n\t\t\t\t\tStaticText '102'\n\t\t\tlistitem ''\n\t\t\t\t[68] link 'Merge requests', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/merge_requests'\n\t\t\t\t\tStaticText '24'\n\t\t\tlistitem ''\n\t\t\t\t[69] link 'CI/CD', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/pipelines'\n\t\t\tlistitem ''\n\t\t\t\t[70] link 'Deployments', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/environments'\n\t\t\tlistitem ''\n\t\t\t\t[71] link 'Packages and registries', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/packages'\n\t\t\tlistitem ''\n\t\t\t\t[72] link 'Monitor', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/incidents'\n\t\t\tlistitem ''\n\t\t\t\t[73] link 'Analytics', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/value_stream_analytics'\n\t\t\tlistitem ''\n\t\t\t\t[74] link 'Wiki', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/wikis/home'\n\t\t\tlistitem ''\n\t\t\t\t[75] link 'Snippets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/snippets'\n\t\t[3] button 'Collapse sidebar'\n\talert '', live='assertive', atomic, relevant='additions text'\n\t\t[4] button 'Dismiss'\n\t\talert '', live='assertive', atomic, relevant='additions text'\n\t\t\tStaticText \"You can't push or pull repositories using SSH until you add an SSH key to your profile.\"\n\t\t\t[19] link 'Add SSH key', url='http://127.0.0.1:8023/-/profile/keys'\n\t\t\t[20] button \"Don't show again\"\n\tnavigation 'Breadcrumbs'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[76] link 'Erik Linder-Nor√©n', url='http://127.0.0.1:8023/eriklindernoren'\n\t\t\tlistitem ''\n\t\t\t\t[77] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tmain ''\n\t\tStaticText 'P'\n\t\theading 'PyTorch-GAN'\n\t\tStaticText 'Project ID: 86'\n\t\t[5] button 'Copy project ID', live='polite', relevant='additions text'\n\t\t[6] link 'Request Access', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/project_members/request_access'\n\t\t[7] button '', hasPopup='menu', expanded=False\n\t\t[8] button 'Star'\n\t\t[9] link '45', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/starrers'\n\t\t[10] link 'Fork', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks/new'\n\t\t[11] link '0', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[177] link '193 Commits', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commits/master'\n\t\t\t\t\t\t[186] strong ''\n\t\t\t\t\t\t\tStaticText '193'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[178] link '25 Branches', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/branches'\n\t\t\t\t\t\t[187] strong ''\n\t\t\t\t\t\t\tStaticText '25'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[179] link '0 Tags', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tags'\n\t\t\t\t\t\t[188] strong ''\n\t\t\t\t\t\t\tStaticText '0'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[180] strong ''\n\t\t\t\t\t\tStaticText '184.7 MB'\n\t\t\t\t\tStaticText 'Project Storage'\n\t\tparagraph ''\n\t\t\tStaticText 'PyTorch implementations of Generative Adversarial Networks.'\n\t\timage 'user avatar', url='https://www.gravatar.com/avatar/8d7c025d033d490fae9de8c637722ba4?s=80&d=identicon'\n\t\t[12] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\tStaticText 'Erik Linder-Nor√©n authored'\n\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\tStaticText '4 years ago'\n\t\t[13] button 'Unverified'\n\t\tgroup ''\n\t\t\tStaticText '36d3c77e'\n\t\t\t[21] button 'Copy commit SHA', live='polite', relevant='additions text'\n\t\t[14] button 'master', hasPopup='menu', expanded=False\n\t\tnavigation 'Files breadcrumb'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[181] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/'\n\t\t\t\tlistitem ''\n\t\t\t\t\tStaticText '/'\n\t\t\t\t\t[182] button 'Add to tree', hasPopup='menu', expanded=False\n\t\t[15] link 'Find file', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/find_file/master'\n\t\t[16] link 'Web IDE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#modal-confirm-fork-webide'\n\t\t[17] button 'Download'\n\t\t\tStaticText 'Select Archive Format'\n\t\t[18] link 'Clone', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[78] link 'README', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\tlistitem ''\n\t\t\t\t[79] link 'MIT License', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\ttable 'Files, directories, and submodules in the path / for commit reference master', live='polite', relevant='additions text'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcolumnheader 'Name'\n\t\t\t\t\tcolumnheader 'Last commit'\n\t\t\t\t\tcolumnheader 'Last update'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcell 'assets'\n\t\t\t\t\t\t[189] link 'assets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/assets'\n\t\t\t\t\tcell 'adds clustergan gif'\n\t\t\t\t\t\t[190] link 'adds clustergan gif', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:52pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'data'\n\t\t\t\t\t\t[191] link 'data', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/data'\n\t\t\t\t\tcell 'Figures'\n\t\t\t\t\t\t[192] link 'Figures', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 23, 2018 8:13pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'implementations'\n\t\t\t\t\t\t[193] link 'implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/implementations'\n\t\t\t\t\tcell 'Adds single clustergan script'\n\t\t\t\t\t\t[194] link 'Adds single clustergan script', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:43am GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell '.gitignore'\n\t\t\t\t\t\t[195] link '.gitignore', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore'\n\t\t\t\t\tcell 'MNIST normalization. Black refactoring.'\n\t\t\t\t\t\t[196] link 'MNIST normalization. Black refactoring.', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Mar 28, 2019 8:55pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'LICENSE'\n\t\t\t\t\t\t[197] link 'LICENSE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\t\t\t\tcell 'Initial commit'\n\t\t\t\t\t\t[198] link 'Initial commit', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 21, 2018 7:06pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'README.md'\n\t\t\t\t\t\t[199] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t\tcell 'Update README.md'\n\t\t\t\t\t\t[200] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\t\t\t\tcell '4 years ago'\n\t\t\t\t\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '4 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'requirements.txt'\n\t\t\t\t\t\t[201] link 'requirements.txt', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt'\n\t\t\t\t\tcell 'Added PyTorch 0.4.0 to requirements'\n\t\t\t\t\t\t[202] link 'Added PyTorch 0.4.0 to requirements', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'May 25, 2018 4:49am GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\tarticle ''\n\t\t\t[22] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t[80] strong ''\n\t\t\t\t\tStaticText 'README.md'\n\t\t\tparagraph ''\n\t\t\t\t[81] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\tparagraph ''\n\t\t\t\t[82] strong ''\n\t\t\t\t\tStaticText 'This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at'\n\t\t\t\t\t[183] link 'eriklindernoren@gmail.com', url='mailto:eriklindernoren@gmail.com'\n\t\t\t\t\tStaticText '.'\n\t\t\theading 'PyTorch-GAN'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed.'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'See also: '\n\t\t\t\t[83] link 'Keras-GAN', url='https://github.com/eriklindernoren/Keras-GAN'\n\t\t\theading 'Table of Contents'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[184] link 'Installation', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#installation'\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[185] link 'Implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#implementations'\n\t\t\t\t\tlist ''\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[203] link 'Auxiliary Classifier GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#auxiliary-classifier-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[204] link 'Adversarial Autoencoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#adversarial-autoencoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[205] link 'BEGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#began'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[206] link 'BicycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#bicyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[207] link 'Boundary-Seeking GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#boundary-seeking-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[208] link 'Cluster GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cluster-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[209] link 'Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[210] link 'Context-Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[211] link 'Context Encoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-encoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[212] link 'Coupled GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#coupled-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[213] link 'CycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[214] link 'Deep Convolutional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#deep-convolutional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[215] link 'DiscoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#discogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[216] link 'DRAGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dragan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[217] link 'DualGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dualgan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[218] link 'Energy-Based GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#energy-based-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[219] link 'Enhanced Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#enhanced-super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[220] link 'GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[221] link 'InfoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#infogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[222] link 'Least Squares GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#least-squares-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[223] link 'MUNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#munit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[224] link 'Pix2Pix', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pix2pix'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[225] link 'PixelDA', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pixelda'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[226] link 'Relativistic GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#relativistic-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[227] link 'Semi-Supervised GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#semi-supervised-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[228] link 'Softmax GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#softmax-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[229] link 'StarGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#stargan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[230] link 'Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[231] link 'UNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#unit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[232] link 'Wasserstein GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[233] link 'Wasserstein GAN GP', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-gp'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[234] link 'Wasserstein GAN DIV', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-div'\n\t\t\theading 'Installation'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ git clone https://github.com/eriklindernoren/PyTorch-GAN  $ cd PyTorch-GAN/  $ sudo pip3 install -r requirements.txt'\n\t\t\t[23] button ''\n\t\t\theading 'Implementations'\n\t\t\theading 'Auxiliary Classifier GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Auxiliary Classifier Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena, Christopher Olah, Jonathon Shlens'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.'\n\t\t\tparagraph ''\n\t\t\t\t[84] link '[Paper]', url='https://arxiv.org/abs/1610.09585'\n\t\t\t\tStaticText ''\n\t\t\t\t[85] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/acgan/  $ python3 acgan.py'\n\t\t\t[24] button ''\n\t\t\tparagraph ''\n\t\t\t\t[86] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\theading 'Adversarial Autoencoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Adversarial Autoencoder'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'n this paper, we propose the \"adversarial autoencoder\" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.'\n\t\t\tparagraph ''\n\t\t\t\t[87] link '[Paper]', url='https://arxiv.org/abs/1511.05644'\n\t\t\t\tStaticText ''\n\t\t\t\t[88] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/aae/  $ python3 aae.py'\n\t\t\t[25] button ''\n\t\t\theading 'BEGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'BEGAN: Boundary Equilibrium Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'David Berthelot, Thomas Schumm, Luke Metz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure.'\n\t\t\tparagraph ''\n\t\t\t\t[89] link '[Paper]', url='https://arxiv.org/abs/1703.10717'\n\t\t\t\tStaticText ''\n\t\t\t\t[90] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/began/  $ python3 began.py'\n\t\t\t[26] button ''\n\t\t\theading 'BicycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Toward Multimodal Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \\\\\\\\emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.'\n\t\t\tparagraph ''\n\t\t\t\t[91] link '[Paper]', url='https://arxiv.org/abs/1711.11586'\n\t\t\t\tStaticText ''\n\t\t\t\t[92] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[93] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/bicyclegan/  $ python3 bicyclegan.py'\n\t\t\t[27] button ''\n\t\t\tparagraph ''\n\t\t\t\t[94] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Various style translations by varying the latent code.'\n\t\t\theading 'Boundary-Seeking GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Boundary-Seeking Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning.'\n\t\t\tparagraph ''\n\t\t\t\t[95] link '[Paper]', url='https://arxiv.org/abs/1702.08431'\n\t\t\t\tStaticText ''\n\t\t\t\t[96] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/bgan/  $ python3 bgan.py'\n\t\t\t[28] button ''\n\t\t\theading 'Cluster GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ClusterGAN: Latent Space Clustering in Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.'\n\t\t\tparagraph ''\n\t\t\t\t[97] link '[Paper]', url='https://arxiv.org/abs/1809.03627'\n\t\t\t\tStaticText ''\n\t\t\t\t[98] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Code based on a full PyTorch'\n\t\t\t\t[99] link '[implementation]', url='https://github.com/zhampel/clusterGAN'\n\t\t\t\tStaticText '.'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cluster_gan/  $ python3 clustergan.py'\n\t\t\t[29] button ''\n\t\t\tparagraph ''\n\t\t\t\t[100] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\theading 'Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Conditional Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Mehdi Mirza, Simon Osindero'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.'\n\t\t\tparagraph ''\n\t\t\t\t[101] link '[Paper]', url='https://arxiv.org/abs/1411.1784'\n\t\t\t\tStaticText ''\n\t\t\t\t[102] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cgan/  $ python3 cgan.py'\n\t\t\t[30] button ''\n\t\t\tparagraph ''\n\t\t\t\t[103] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\theading 'Context-Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Emily Denton, Sam Gross, Rob Fergus'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods.'\n\t\t\tparagraph ''\n\t\t\t\t[104] link '[Paper]', url='https://arxiv.org/abs/1611.06430'\n\t\t\t\tStaticText ''\n\t\t\t\t[105] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ccgan/  $ python3 ccgan.py'\n\t\t\t[31] button ''\n\t\t\theading 'Context Encoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Context Encoders: Feature Learning by Inpainting'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.'\n\t\t\tparagraph ''\n\t\t\t\t[106] link '[Paper]', url='https://arxiv.org/abs/1604.07379'\n\t\t\t\tStaticText ''\n\t\t\t\t[107] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/context_encoder/  <follow steps at the top of context_encoder.py>  $ python3 context_encoder.py'\n\t\t\t[32] button ''\n\t\t\tparagraph ''\n\t\t\t\t[108] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows: Masked | Inpainted | Original | Masked | Inpainted | Original'\n\t\t\theading 'Coupled GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Coupled Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Oncel Tuzel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation.'\n\t\t\tparagraph ''\n\t\t\t\t[109] link '[Paper]', url='https://arxiv.org/abs/1606.07536'\n\t\t\t\tStaticText ''\n\t\t\t\t[110] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cogan/  $ python3 cogan.py'\n\t\t\t[33] button ''\n\t\t\tparagraph ''\n\t\t\t\t[111] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generated MNIST and MNIST-M images'\n\t\t\theading 'CycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X‚ÜíY such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y‚ÜíX and introduce a cycle consistency loss to push F(G(X))‚âàX (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.'\n\t\t\tparagraph ''\n\t\t\t\t[112] link '[Paper]', url='https://arxiv.org/abs/1703.10593'\n\t\t\t\tStaticText ''\n\t\t\t\t[113] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[114] link '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh monet2photo  $ cd ../implementations/cyclegan/  $ python3 cyclegan.py --dataset_name monet2photo'\n\t\t\t[34] button ''\n\t\t\tparagraph ''\n\t\t\t\t[115] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Monet to photo translations.'\n\t\t\theading 'Deep Convolutional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Deep Convolutional Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alec Radford, Luke Metz, Soumith Chintala'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.'\n\t\t\tparagraph ''\n\t\t\t\t[116] link '[Paper]', url='https://arxiv.org/abs/1511.06434'\n\t\t\t\tStaticText ''\n\t\t\t\t[117] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dcgan/  $ python3 dcgan.py'\n\t\t\t[35] button ''\n\t\t\tparagraph ''\n\t\t\t\t[118] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\theading 'DiscoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Learning to Discover Cross-Domain Relations with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity.'\n\t\t\tparagraph ''\n\t\t\t\t[119] link '[Paper]', url='https://arxiv.org/abs/1703.05192'\n\t\t\t\tStaticText ''\n\t\t\t\t[120] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py'\n\t\t\tparagraph ''\n\t\t\t\t[121] link '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/discogan/  $ python3 discogan.py --dataset_name edges2shoes'\n\t\t\t[36] button ''\n\t\t\tparagraph ''\n\t\t\t\t[122] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real image from domain A (2) Translated image from domain A (3) Reconstructed image from domain A (4) Real image from domain B (5) Translated image from domain B (6) Reconstructed image from domain B'\n\t\t\theading 'DRAGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'On Convergence and Stability of GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.'\n\t\t\tparagraph ''\n\t\t\t\t[123] link '[Paper]', url='https://arxiv.org/abs/1705.07215'\n\t\t\t\tStaticText ''\n\t\t\t\t[124] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dragan/  $ python3 dragan.py'\n\t\t\t[37] button ''\n\t\t\theading 'DualGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'DualGAN: Unsupervised Dual Learning for Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Zili Yi, Hao Zhang, Ping Tan, Minglun Gong'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data.'\n\t\t\tparagraph ''\n\t\t\t\t[125] link '[Paper]', url='https://arxiv.org/abs/1704.02510'\n\t\t\t\tStaticText ''\n\t\t\t\t[126] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/dualgan/  $ python3 dualgan.py --dataset_name facades'\n\t\t\t[38] button ''\n\t\t\theading 'Energy-Based GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Energy-based Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Junbo Zhao, Michael Mathieu, Yann LeCun'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.'\n\t\t\tparagraph ''\n\t\t\t\t[127] link '[Paper]', url='https://arxiv.org/abs/1609.03126'\n\t\t\t\tStaticText ''\n\t\t\t\t[128] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ebgan/  $ python3 ebgan.py'\n\t\t\t[39] button ''\n\t\t\theading 'Enhanced Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at'\n\t\t\t\t[129] link 'this https URL', url='https://github.com/xinntao/ESRGAN'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[130] link '[Paper]', url='https://arxiv.org/abs/1809.00219'\n\t\t\t\tStaticText ''\n\t\t\t\t[131] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/esrgan/  <follow steps at the top of esrgan.py>  $ python3 esrgan.py'\n\t\t\t[40] button ''\n\t\t\tparagraph ''\n\t\t\t\t[132] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | ESRGAN'\n\t\t\theading 'GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.'\n\t\t\tparagraph ''\n\t\t\t\t[133] link '[Paper]', url='https://arxiv.org/abs/1406.2661'\n\t\t\t\tStaticText ''\n\t\t\t\t[134] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/gan/  $ python3 gan.py'\n\t\t\t[41] button ''\n\t\t\tparagraph ''\n\t\t\t\t[135] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\theading 'InfoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.'\n\t\t\tparagraph ''\n\t\t\t\t[136] link '[Paper]', url='https://arxiv.org/abs/1606.03657'\n\t\t\t\tStaticText ''\n\t\t\t\t[137] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/infogan/  $ python3 infogan.py'\n\t\t\t[42] button ''\n\t\t\tparagraph ''\n\t\t\t\t[138] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying categorical latent variable by column.'\n\t\t\tparagraph ''\n\t\t\t\t[139] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying continuous latent variable by row.'\n\t\t\theading 'Least Squares GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Least Squares Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson œá2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.'\n\t\t\tparagraph ''\n\t\t\t\t[140] link '[Paper]', url='https://arxiv.org/abs/1611.04076'\n\t\t\t\tStaticText ''\n\t\t\t\t[141] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/lsgan/  $ python3 lsgan.py'\n\t\t\t[43] button ''\n\t\t\theading 'MUNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Multimodal Unsupervised Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at'\n\t\t\t\t[142] link 'this https URL', url='https://github.com/nvlabs/MUNIT'\n\t\t\tparagraph ''\n\t\t\t\t[143] link '[Paper]', url='https://arxiv.org/abs/1804.04732'\n\t\t\t\tStaticText ''\n\t\t\t\t[144] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/munit/  $ python3 munit.py --dataset_name edges2shoes'\n\t\t\t[44] button ''\n\t\t\tparagraph ''\n\t\t\t\t[145] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Results by varying the style code.'\n\t\t\theading 'Pix2Pix'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation with Conditional Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.'\n\t\t\tparagraph ''\n\t\t\t\t[146] link '[Paper]', url='https://arxiv.org/abs/1611.07004'\n\t\t\t\tStaticText ''\n\t\t\t\t[147] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py'\n\t\t\tparagraph ''\n\t\t\t\t[148] link '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/pix2pix/  $ python3 pix2pix.py --dataset_name facades'\n\t\t\t[45] button ''\n\t\t\tparagraph ''\n\t\t\t\t[149] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) The condition for the generator (2) Generated image based of condition (3) The true corresponding image to the condition'\n\t\t\theading 'PixelDA'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training.'\n\t\t\tparagraph ''\n\t\t\t\t[150] link '[Paper]', url='https://arxiv.org/abs/1612.05424'\n\t\t\t\tStaticText ''\n\t\t\t\t[151] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py'\n\t\t\theading 'MNIST to MNIST-M Classification'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy.'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/pixelda/  $ python3 pixelda.py'\n\t\t\t[46] button ''\n\t\t\ttable ''\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcolumnheader 'Method'\n\t\t\t\t\t\tcolumnheader 'Accuracy'\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'Naive'\n\t\t\t\t\t\tcell '55%'\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'PixelDA'\n\t\t\t\t\t\tcell '95%'\n\t\t\tparagraph ''\n\t\t\t\t[152] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real images from MNIST (2) Translated images from MNIST to MNIST-M (3) Examples of images from MNIST-M'\n\t\t\theading 'Relativistic GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'The relativistic discriminator: a key element missing from standard GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alexia Jolicoeur-Martineau'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.'\n\t\t\tparagraph ''\n\t\t\t\t[153] link '[Paper]', url='https://arxiv.org/abs/1807.00734'\n\t\t\t\tStaticText ''\n\t\t\t\t[154] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/relativistic_gan/  $ python3 relativistic_gan.py                 # Relativistic Standard GAN  $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN'\n\t\t\t[47] button ''\n\t\t\theading 'Semi-Supervised GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN.'\n\t\t\tparagraph ''\n\t\t\t\t[155] link '[Paper]', url='https://arxiv.org/abs/1606.01583'\n\t\t\t\tStaticText ''\n\t\t\t\t[156] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/sgan/  $ python3 sgan.py'\n\t\t\t[48] button ''\n\t\t\theading 'Softmax GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Softmax GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Min Lin'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training.'\n\t\t\tparagraph ''\n\t\t\t\t[157] link '[Paper]', url='https://arxiv.org/abs/1704.06191'\n\t\t\t\tStaticText ''\n\t\t\t\t[158] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/softmax_gan/  $ python3 softmax_gan.py'\n\t\t\t[49] button ''\n\t\t\theading 'StarGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText \"Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.\"\n\t\t\tparagraph ''\n\t\t\t\t[159] link '[Paper]', url='https://arxiv.org/abs/1711.09020'\n\t\t\t\tStaticText ''\n\t\t\t\t[160] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/stargan/  <follow steps at the top of stargan.py>  $ python3 stargan.py'\n\t\t\t[50] button ''\n\t\t\tparagraph ''\n\t\t\t\t[161] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged'\n\t\t\theading 'Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.'\n\t\t\tparagraph ''\n\t\t\t\t[162] link '[Paper]', url='https://arxiv.org/abs/1609.04802'\n\t\t\t\tStaticText ''\n\t\t\t\t[163] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py'\n\t\t\tparagraph ''\n\t\t\t\t[164] link '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/srgan/  <follow steps at the top of srgan.py>  $ python3 srgan.py'\n\t\t\t[51] button ''\n\t\t\tparagraph ''\n\t\t\t\t[165] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | SRGAN'\n\t\t\theading 'UNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Image-to-Image Translation Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Thomas Breuel, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this'\n\t\t\t\t[166] link 'https URL', url='https://github.com/mingyuliutw/unit'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[167] link '[Paper]', url='https://arxiv.org/abs/1703.00848'\n\t\t\t\tStaticText ''\n\t\t\t\t[168] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh apple2orange  $ cd implementations/unit/  $ python3 unit.py --dataset_name apple2orange'\n\t\t\t[52] button ''\n\t\t\theading 'Wasserstein GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Martin Arjovsky, Soumith Chintala, L√©on Bottou'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.'\n\t\t\tparagraph ''\n\t\t\t\t[169] link '[Paper]', url='https://arxiv.org/abs/1701.07875'\n\t\t\t\tStaticText ''\n\t\t\t\t[170] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan/  $ python3 wgan.py'\n\t\t\t[53] button ''\n\t\t\theading 'Wasserstein GAN GP'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Improved Training of Wasserstein GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.'\n\t\t\tparagraph ''\n\t\t\t\t[171] link '[Paper]', url='https://arxiv.org/abs/1704.00028'\n\t\t\t\tStaticText ''\n\t\t\t\t[172] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_gp/  $ python3 wgan_gp.py'\n\t\t\t[54] button ''\n\t\t\tparagraph ''\n\t\t\t\t[173] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\theading 'Wasserstein GAN DIV'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein Divergence for GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods.'\n\t\t\tparagraph ''\n\t\t\t\t[174] link '[Paper]', url='https://arxiv.org/abs/1712.01026'\n\t\t\t\tStaticText ''\n\t\t\t\t[175] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_div/  $ python3 wgan_div.py'\n\t\t\t[55] button ''\n\t\t\tparagraph ''\n\t\t\t\t[176] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'",
    "action": {
      "code": "click('18')",
      "thought": "The goal requires showing the command to clone this repository using SSH. The SSH clone URL is revealed only when the Clone dropdown is opened. Therefore the next step is to click the ‚ÄúClone‚Äù button to expose the SSH URL.",
      "type": "click",
      "args": {
        "bid": "18"
      },
      "selected_element": {
        "nodeId": "16476",
        "ignored": false,
        "role": {
          "type": "role",
          "value": "link"
        },
        "chromeRole": {
          "type": "internalRole",
          "value": 110
        },
        "name": {
          "type": "computedString",
          "value": "Clone",
          "sources": [
            {
              "type": "relatedElement",
              "attribute": "aria-labelledby"
            },
            {
              "type": "attribute",
              "attribute": "aria-label"
            },
            {
              "type": "contents",
              "value": {
                "type": "computedString",
                "value": "Clone"
              }
            },
            {
              "type": "attribute",
              "attribute": "title",
              "superseded": true
            }
          ]
        },
        "properties": [
          {
            "name": "focusable",
            "value": {
              "type": "booleanOrUndefined",
              "value": true
            }
          },
          {
            "name": "url",
            "value": {
              "type": "string",
              "value": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#"
            }
          }
        ],
        "parentId": "16474",
        "childIds": [
          "16479",
          "14234"
        ],
        "backendDOMNodeId": 16476,
        "browsergym_id": "890",
        "weboperator_id": 18
      }
    },
    "action_error": "",
    "obs_description": "We are on the repository page for **eriklindernoren/PyTorch-GAN**.  \nThe page contains a ‚ÄúClone‚Äù button (ID 18). Clicking this button opens a dropdown with the clone URLs, including an SSH URL such as  \n```\nssh://git@gitlab.com/eriklindernoren/PyTorch-GAN.git\n```",
    "http_requests": [
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
        "header": {
          "referer": "http://127.0.0.1:8023/search?search=GAN&nav_source=navbar",
          "upgrade-insecure-requests": "1",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "sec-ch-ua-platform": "\"Linux\""
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application_utilities-9738b4b8a2a962938594e4e9a61166f460a24bef1c8d8513d8c5a2dab6c234d1.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/highlight/themes/white-50af3266b171499d73d3026e07fecd6a0fbd80766f824cd0c2866752b8182752.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/runtime.41bbcd8d.bundle.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/main.cc246a51.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/graphql.a062ade3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-IssuablePopoverBundle-pages.admin.application_settings-pages.admin.application_settings.ci_c-5b1a6745.a22d110e.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/shortcutsBundle.aa6bffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/5.7e84824d.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.groups.new-pages.ide-pages.import.gitlab_projects.new-pages.import.manifest.new-pages.-c71aa43f.e82c59ff.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.groups.boards-pages.groups.details-pages.groups.show-pages.projects-pages.projects.act-07083c7a.5e616d60.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects-pages.projects.activity-pages.projects.alert_management.details-pages.project-d4dac98f.27f15655.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.groups.details-pages.groups.group_members-pages.groups.merge_requests-pages.groups.sho-2c913a08.4577635d.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.blob.show-pages.projects.show-pages.projects.snippets.edit-pages.projects.sni-dd84f7c7.895dff7a.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.blob.show-pages.projects.show-pages.projects.snippets.show-pages.projects.tre-25c821a4.36747154.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.blob.show-pages.projects.forks.new-pages.projects.show-pages.projects.tree.show.92194797.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.blob.show-pages.projects.show-pages.projects.tree.show.4070c2a3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.show-pages.projects.tree.show.cb6b5dd9.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/pages.projects.show.3999e644.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/refs/master/logs_tree/?format=json&offset=0",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md?format=json&viewer=rich",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "POST",
        "url": "http://127.0.0.1:8023/api/graphql",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "WFF4b81XYR0+A09b6cnamYIP44uGA7KdgoIEN0YQ3vjXqpRH7mKQGjqCaV1XbLwNyDe5uKSbEOloLCXoqfG7MQ==",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "content-type": "application/json",
          "x-gitlab-feature-category": "projects"
        },
        "payload": "{\"query\":\"query pathLastCommit($projectPath: ID!, $path: String, $ref: String!) {\\n  project(fullPath: $projectPath) {\\n    __typename\\n    id\\n    repository {\\n      __typename\\n      paginatedTree(path: $path, ref: $ref) {\\n        __typename\\n        nodes {\\n          __typename\\n          lastCommit {\\n            __typename\\n            id\\n            sha\\n            title\\n            titleHtml\\n            descriptionHtml\\n            message\\n            webPath\\n            authoredDate\\n            authorName\\n            authorGravatar\\n            author {\\n              __typename\\n              id\\n              name\\n              avatarUrl\\n              webPath\\n            }\\n            signatureHtml\\n            pipelines(ref: $ref, first: 1) {\\n              __typename\\n              edges {\\n                __typename\\n                node {\\n                  __typename\\n                  id\\n                  detailedStatus {\\n                    __typename\\n                    id\\n                    detailsPath\\n                    icon\\n                    tooltip\\n                    text\\n                    group\\n                  }\\n                }\\n              }\\n            }\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\n\",\"variables\":{\"projectPath\":\"eriklindernoren/PyTorch-GAN\",\"ref\":\"master\",\"path\":\"\"}}"
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/project-a3a985d5f2b064fbaf60b28ceeccd80b6218f176535673020e84a04ea7612c65.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/page_bundles/tree-84ff27d40d7ca999fb0db1276a53fac19fdb1290e05b4bae9d5c1baf485252b0.css",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "blob:http://127.0.0.1:8023/85d97639-83bf-4997-a505-85ad2955a0e6",
        "header": {
          "accept": "*/*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/hello.b8beffce.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/commons-pages.projects.branches.new-pages.projects.commits.show-pages.projects.pages.new-pages.proje-dc3af1d1.8b77aaf3.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/treeList.3d8d6a75.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/api/v4/projects/86/repository/branches?search=&per_page=20",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "N47eKQSr+VznBeWKq0w5WjLNzbOhHCH9sa7oZ+Se3rW4dTIBJ54IW+OEw4wV6V/OePWXgIOEg4lbAMm4C3+7fA==",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/api/v4/projects/86/repository/tags?search=&per_page=20",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "N47eKQSr+VznBeWKq0w5WjLNzbOhHCH9sa7oZ+Se3rW4dTIBJ54IW+OEw4wV6V/OePWXgIOEg4lbAMm4C3+7fA==",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "x-requested-with": "XMLHttpRequest",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "application/json, text/plain, */*"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "https://www.gravatar.com/avatar/8d7c025d033d490fae9de8c637722ba4?s=80&d=identicon",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "POST",
        "url": "http://127.0.0.1:8023/api/graphql",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "x-csrf-token": "N47eKQSr+VznBeWKq0w5WjLNzbOhHCH9sa7oZ+Se3rW4dTIBJ54IW+OEw4wV6V/OePWXgIOEg4lbAMm4C3+7fA==",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "accept": "*/*",
          "content-type": "application/json",
          "x-gitlab-feature-category": "projects"
        },
        "payload": "[{\"operationName\":\"getPermissions\",\"variables\":{\"projectPath\":\"eriklindernoren/PyTorch-GAN\"},\"query\":\"query getPermissions($projectPath: ID!) {\\n  project(fullPath: $projectPath) {\\n    id\\n    __typename\\n    userPermissions {\\n      __typename\\n      pushCode\\n      forkProject\\n      createMergeRequestIn\\n    }\\n  }\\n}\\n\"},{\"operationName\":\"getPaginatedTree\",\"variables\":{\"projectPath\":\"eriklindernoren/PyTorch-GAN\",\"ref\":\"master\",\"path\":\"/\",\"nextPageCursor\":\"\",\"pageSize\":100},\"query\":\"fragment TreeEntry on Entry {\\n  __typename\\n  id\\n  sha\\n  name\\n  flatPath\\n  type\\n}\\n\\nquery getPaginatedTree($projectPath: ID!, $path: String, $ref: String!, $nextPageCursor: String) {\\n  project(fullPath: $projectPath) {\\n    id\\n    __typename\\n    repository {\\n      __typename\\n      paginatedTree(path: $path, ref: $ref, after: $nextPageCursor) {\\n        __typename\\n        pageInfo {\\n          __typename\\n          endCursor\\n          startCursor\\n          hasNextPage\\n        }\\n        nodes {\\n          __typename\\n          trees {\\n            __typename\\n            nodes {\\n              ...TreeEntry\\n              webPath\\n              __typename\\n            }\\n          }\\n          submodules {\\n            __typename\\n            nodes {\\n              ...TreeEntry\\n              webUrl\\n              treeUrl\\n              __typename\\n            }\\n          }\\n          blobs {\\n            __typename\\n            nodes {\\n              ...TreeEntry\\n              mode\\n              webPath\\n              lfsOid\\n              __typename\\n            }\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\n\"}]"
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-globalSearch-top_nav.138d3d52.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/vendors-top_nav.679da758.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/webpack/top_nav.e4e15f50.chunk.js",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/file_icons-958d18a1c33aa82a81e2eb1ffbffc33131d501c41ad95838a70b089e5ffbd7a0.svg",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/assets/icon_anchor-297aa9b0225eff3d6d0da74ce042a0ed5575b92aa66b7109a5e060a795b42e36.svg",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/assets/application-1e8c169a1e3fd710539d4a64b60f69b9d1bca3ec4b8272d22f36b158ffc276fe.css",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      },
      {
        "method": "GET",
        "url": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif",
        "header": {
          "sec-ch-ua-platform": "\"Linux\"",
          "referer": "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN",
          "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/139.0.7258.5 Safari/537.36",
          "sec-ch-ua": "\"Not;A=Brand\";v=\"99\", \"HeadlessChrome\";v=\"139\", \"Chromium\";v=\"139\"",
          "sec-ch-ua-mobile": "?0"
        },
        "payload": ""
      }
    ]
  },
  {
    "open_pages_titles": [
      "Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab', focused, url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[56] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[57] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[58] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[59] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[60] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[61] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[62] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[63] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tcomplementary 'Project navigation'\n\t\tlist ''\n\t\t\tlistitem 'PyTorch-GAN'\n\t\t\t\t[64] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\t\t\tlistitem ''\n\t\t\t\t[65] link 'Project information', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/activity'\n\t\t\tlistitem ''\n\t\t\t\t[66] link 'Repository', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master'\n\t\t\tlistitem ''\n\t\t\t\t[67] link 'Issues', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/issues'\n\t\t\t\t\tStaticText '102'\n\t\t\tlistitem ''\n\t\t\t\t[68] link 'Merge requests', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/merge_requests'\n\t\t\t\t\tStaticText '24'\n\t\t\tlistitem ''\n\t\t\t\t[69] link 'CI/CD', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/pipelines'\n\t\t\tlistitem ''\n\t\t\t\t[70] link 'Deployments', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/environments'\n\t\t\tlistitem ''\n\t\t\t\t[71] link 'Packages and registries', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/packages'\n\t\t\tlistitem ''\n\t\t\t\t[72] link 'Monitor', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/incidents'\n\t\t\tlistitem ''\n\t\t\t\t[73] link 'Analytics', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/value_stream_analytics'\n\t\t\tlistitem ''\n\t\t\t\t[74] link 'Wiki', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/wikis/home'\n\t\t\tlistitem ''\n\t\t\t\t[75] link 'Snippets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/snippets'\n\t\t[3] button 'Collapse sidebar'\n\talert '', live='assertive', atomic, relevant='additions text'\n\t\t[4] button 'Dismiss'\n\t\talert '', live='assertive', atomic, relevant='additions text'\n\t\t\tStaticText \"You can't push or pull repositories using SSH until you add an SSH key to your profile.\"\n\t\t\t[19] link 'Add SSH key', url='http://127.0.0.1:8023/-/profile/keys'\n\t\t\t[20] button \"Don't show again\"\n\tnavigation 'Breadcrumbs'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[76] link 'Erik Linder-Nor√©n', url='http://127.0.0.1:8023/eriklindernoren'\n\t\t\tlistitem ''\n\t\t\t\t[77] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tmain ''\n\t\tStaticText 'P'\n\t\theading 'PyTorch-GAN'\n\t\tStaticText 'Project ID: 86'\n\t\t[5] button 'Copy project ID', live='polite', relevant='additions text'\n\t\t[6] link 'Request Access', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/project_members/request_access'\n\t\t[7] button '', hasPopup='menu', expanded=False\n\t\t[8] button 'Star'\n\t\t[9] link '45', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/starrers'\n\t\t[10] link 'Fork', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks/new'\n\t\t[11] link '0', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[188] link '193 Commits', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commits/master'\n\t\t\t\t\t\t[197] strong ''\n\t\t\t\t\t\t\tStaticText '193'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[189] link '25 Branches', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/branches'\n\t\t\t\t\t\t[198] strong ''\n\t\t\t\t\t\t\tStaticText '25'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[190] link '0 Tags', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tags'\n\t\t\t\t\t\t[199] strong ''\n\t\t\t\t\t\t\tStaticText '0'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[191] strong ''\n\t\t\t\t\t\tStaticText '184.7 MB'\n\t\t\t\t\tStaticText 'Project Storage'\n\t\tparagraph ''\n\t\t\tStaticText 'PyTorch implementations of Generative Adversarial Networks.'\n\t\timage 'user avatar', url='https://www.gravatar.com/avatar/8d7c025d033d490fae9de8c637722ba4?s=80&d=identicon'\n\t\t[12] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\tStaticText 'Erik Linder-Nor√©n authored'\n\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\tStaticText '4 years ago'\n\t\t[13] button 'Unverified'\n\t\tgroup ''\n\t\t\tStaticText '36d3c77e'\n\t\t\t[21] button 'Copy commit SHA', live='polite', relevant='additions text'\n\t\t[14] button 'master', hasPopup='menu', expanded=False\n\t\tnavigation 'Files breadcrumb'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[192] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/'\n\t\t\t\tlistitem ''\n\t\t\t\t\tStaticText '/'\n\t\t\t\t\t[193] button 'Add to tree', hasPopup='menu', expanded=False\n\t\t[15] link 'Find file', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/find_file/master'\n\t\t[16] link 'Web IDE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#modal-confirm-fork-webide'\n\t\t[17] button 'Download'\n\t\t\tStaticText 'Select Archive Format'\n\t\t[18] link 'Clone', focused, expanded=True, url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[78] LabelText ''\n\t\t\t\t\tStaticText 'Clone with SSH'\n\t\t\t\t[79] textbox 'Repository clone URL' value='ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t\tStaticText 'ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t[80] button 'Copy URL', live='polite', relevant='additions text'\n\t\t\tlistitem ''\n\t\t\t\t[81] LabelText ''\n\t\t\t\t\tStaticText 'Clone with HTTP'\n\t\t\t\t[82] textbox 'Repository clone URL' value='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t\tStaticText 'http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t[83] button 'Copy URL', live='polite', relevant='additions text'\n\t\t\tlistitem ''\n\t\t\tlistitem ''\n\t\t\t\t[84] LabelText ''\n\t\t\t\t\tStaticText 'Open in your IDE'\n\t\t\t\t[85] link 'Visual Studio Code (SSH)', url='vscode://vscode.git/clone?url=ssh%3A%2F%2Fgit%40127.0.0.1%3A2222%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[86] link 'Visual Studio Code (HTTPS)', url='vscode://vscode.git/clone?url=http%3A%2F%2F127.0.0.1%3A8023%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[87] link 'IntelliJ IDEA (SSH)', url='jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=ssh%3A%2F%2Fgit%40127.0.0.1%3A2222%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[88] link 'IntelliJ IDEA (HTTPS)', url='jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=http%3A%2F%2F127.0.0.1%3A8023%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[89] link 'README', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\tlistitem ''\n\t\t\t\t[90] link 'MIT License', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\ttable 'Files, directories, and submodules in the path / for commit reference master', live='polite', relevant='additions text'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcolumnheader 'Name'\n\t\t\t\t\tcolumnheader 'Last commit'\n\t\t\t\t\tcolumnheader 'Last update'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcell 'assets'\n\t\t\t\t\t\t[200] link 'assets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/assets'\n\t\t\t\t\tcell 'adds clustergan gif'\n\t\t\t\t\t\t[201] link 'adds clustergan gif', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:52pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'data'\n\t\t\t\t\t\t[202] link 'data', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/data'\n\t\t\t\t\tcell 'Figures'\n\t\t\t\t\t\t[203] link 'Figures', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 23, 2018 8:13pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'implementations'\n\t\t\t\t\t\t[204] link 'implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/implementations'\n\t\t\t\t\tcell 'Adds single clustergan script'\n\t\t\t\t\t\t[205] link 'Adds single clustergan script', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:43am GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell '.gitignore'\n\t\t\t\t\t\t[206] link '.gitignore', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore'\n\t\t\t\t\tcell 'MNIST normalization. Black refactoring.'\n\t\t\t\t\t\t[207] link 'MNIST normalization. Black refactoring.', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Mar 28, 2019 8:55pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'LICENSE'\n\t\t\t\t\t\t[208] link 'LICENSE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\t\t\t\tcell 'Initial commit'\n\t\t\t\t\t\t[209] link 'Initial commit', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 21, 2018 7:06pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'README.md'\n\t\t\t\t\t\t[210] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t\tcell 'Update README.md'\n\t\t\t\t\t\t[211] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\t\t\t\tcell '4 years ago'\n\t\t\t\t\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '4 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'requirements.txt'\n\t\t\t\t\t\t[212] link 'requirements.txt', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt'\n\t\t\t\t\tcell 'Added PyTorch 0.4.0 to requirements'\n\t\t\t\t\t\t[213] link 'Added PyTorch 0.4.0 to requirements', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'May 25, 2018 4:49am GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\tarticle ''\n\t\t\t[22] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t[91] strong ''\n\t\t\t\t\tStaticText 'README.md'\n\t\t\tparagraph ''\n\t\t\t\t[92] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\tparagraph ''\n\t\t\t\t[93] strong ''\n\t\t\t\t\tStaticText 'This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at'\n\t\t\t\t\t[194] link 'eriklindernoren@gmail.com', url='mailto:eriklindernoren@gmail.com'\n\t\t\t\t\tStaticText '.'\n\t\t\theading 'PyTorch-GAN'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed.'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'See also: '\n\t\t\t\t[94] link 'Keras-GAN', url='https://github.com/eriklindernoren/Keras-GAN'\n\t\t\theading 'Table of Contents'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[195] link 'Installation', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#installation'\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[196] link 'Implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#implementations'\n\t\t\t\t\tlist ''\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[214] link 'Auxiliary Classifier GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#auxiliary-classifier-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[215] link 'Adversarial Autoencoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#adversarial-autoencoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[216] link 'BEGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#began'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[217] link 'BicycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#bicyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[218] link 'Boundary-Seeking GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#boundary-seeking-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[219] link 'Cluster GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cluster-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[220] link 'Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[221] link 'Context-Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[222] link 'Context Encoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-encoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[223] link 'Coupled GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#coupled-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[224] link 'CycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[225] link 'Deep Convolutional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#deep-convolutional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[226] link 'DiscoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#discogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[227] link 'DRAGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dragan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[228] link 'DualGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dualgan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[229] link 'Energy-Based GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#energy-based-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[230] link 'Enhanced Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#enhanced-super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[231] link 'GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[232] link 'InfoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#infogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[233] link 'Least Squares GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#least-squares-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[234] link 'MUNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#munit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[235] link 'Pix2Pix', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pix2pix'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[236] link 'PixelDA', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pixelda'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[237] link 'Relativistic GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#relativistic-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[238] link 'Semi-Supervised GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#semi-supervised-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[239] link 'Softmax GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#softmax-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[240] link 'StarGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#stargan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[241] link 'Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[242] link 'UNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#unit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[243] link 'Wasserstein GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[244] link 'Wasserstein GAN GP', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-gp'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[245] link 'Wasserstein GAN DIV', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-div'\n\t\t\theading 'Installation'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ git clone https://github.com/eriklindernoren/PyTorch-GAN  $ cd PyTorch-GAN/  $ sudo pip3 install -r requirements.txt'\n\t\t\t[23] button ''\n\t\t\theading 'Implementations'\n\t\t\theading 'Auxiliary Classifier GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Auxiliary Classifier Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena, Christopher Olah, Jonathon Shlens'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.'\n\t\t\tparagraph ''\n\t\t\t\t[95] link '[Paper]', url='https://arxiv.org/abs/1610.09585'\n\t\t\t\tStaticText ''\n\t\t\t\t[96] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/acgan/  $ python3 acgan.py'\n\t\t\t[24] button ''\n\t\t\tparagraph ''\n\t\t\t\t[97] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\theading 'Adversarial Autoencoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Adversarial Autoencoder'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'n this paper, we propose the \"adversarial autoencoder\" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.'\n\t\t\tparagraph ''\n\t\t\t\t[98] link '[Paper]', url='https://arxiv.org/abs/1511.05644'\n\t\t\t\tStaticText ''\n\t\t\t\t[99] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/aae/  $ python3 aae.py'\n\t\t\t[25] button ''\n\t\t\theading 'BEGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'BEGAN: Boundary Equilibrium Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'David Berthelot, Thomas Schumm, Luke Metz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure.'\n\t\t\tparagraph ''\n\t\t\t\t[100] link '[Paper]', url='https://arxiv.org/abs/1703.10717'\n\t\t\t\tStaticText ''\n\t\t\t\t[101] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/began/  $ python3 began.py'\n\t\t\t[26] button ''\n\t\t\theading 'BicycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Toward Multimodal Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \\\\\\\\emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.'\n\t\t\tparagraph ''\n\t\t\t\t[102] link '[Paper]', url='https://arxiv.org/abs/1711.11586'\n\t\t\t\tStaticText ''\n\t\t\t\t[103] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[104] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/bicyclegan/  $ python3 bicyclegan.py'\n\t\t\t[27] button ''\n\t\t\tparagraph ''\n\t\t\t\t[105] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Various style translations by varying the latent code.'\n\t\t\theading 'Boundary-Seeking GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Boundary-Seeking Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning.'\n\t\t\tparagraph ''\n\t\t\t\t[106] link '[Paper]', url='https://arxiv.org/abs/1702.08431'\n\t\t\t\tStaticText ''\n\t\t\t\t[107] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/bgan/  $ python3 bgan.py'\n\t\t\t[28] button ''\n\t\t\theading 'Cluster GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ClusterGAN: Latent Space Clustering in Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.'\n\t\t\tparagraph ''\n\t\t\t\t[108] link '[Paper]', url='https://arxiv.org/abs/1809.03627'\n\t\t\t\tStaticText ''\n\t\t\t\t[109] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Code based on a full PyTorch'\n\t\t\t\t[110] link '[implementation]', url='https://github.com/zhampel/clusterGAN'\n\t\t\t\tStaticText '.'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cluster_gan/  $ python3 clustergan.py'\n\t\t\t[29] button ''\n\t\t\tparagraph ''\n\t\t\t\t[111] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\theading 'Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Conditional Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Mehdi Mirza, Simon Osindero'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.'\n\t\t\tparagraph ''\n\t\t\t\t[112] link '[Paper]', url='https://arxiv.org/abs/1411.1784'\n\t\t\t\tStaticText ''\n\t\t\t\t[113] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cgan/  $ python3 cgan.py'\n\t\t\t[30] button ''\n\t\t\tparagraph ''\n\t\t\t\t[114] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\theading 'Context-Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Emily Denton, Sam Gross, Rob Fergus'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods.'\n\t\t\tparagraph ''\n\t\t\t\t[115] link '[Paper]', url='https://arxiv.org/abs/1611.06430'\n\t\t\t\tStaticText ''\n\t\t\t\t[116] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ccgan/  $ python3 ccgan.py'\n\t\t\t[31] button ''\n\t\t\theading 'Context Encoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Context Encoders: Feature Learning by Inpainting'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.'\n\t\t\tparagraph ''\n\t\t\t\t[117] link '[Paper]', url='https://arxiv.org/abs/1604.07379'\n\t\t\t\tStaticText ''\n\t\t\t\t[118] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/context_encoder/  <follow steps at the top of context_encoder.py>  $ python3 context_encoder.py'\n\t\t\t[32] button ''\n\t\t\tparagraph ''\n\t\t\t\t[119] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows: Masked | Inpainted | Original | Masked | Inpainted | Original'\n\t\t\theading 'Coupled GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Coupled Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Oncel Tuzel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation.'\n\t\t\tparagraph ''\n\t\t\t\t[120] link '[Paper]', url='https://arxiv.org/abs/1606.07536'\n\t\t\t\tStaticText ''\n\t\t\t\t[121] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cogan/  $ python3 cogan.py'\n\t\t\t[33] button ''\n\t\t\tparagraph ''\n\t\t\t\t[122] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generated MNIST and MNIST-M images'\n\t\t\theading 'CycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X‚ÜíY such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y‚ÜíX and introduce a cycle consistency loss to push F(G(X))‚âàX (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.'\n\t\t\tparagraph ''\n\t\t\t\t[123] link '[Paper]', url='https://arxiv.org/abs/1703.10593'\n\t\t\t\tStaticText ''\n\t\t\t\t[124] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[125] link '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh monet2photo  $ cd ../implementations/cyclegan/  $ python3 cyclegan.py --dataset_name monet2photo'\n\t\t\t[34] button ''\n\t\t\tparagraph ''\n\t\t\t\t[126] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Monet to photo translations.'\n\t\t\theading 'Deep Convolutional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Deep Convolutional Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alec Radford, Luke Metz, Soumith Chintala'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.'\n\t\t\tparagraph ''\n\t\t\t\t[127] link '[Paper]', url='https://arxiv.org/abs/1511.06434'\n\t\t\t\tStaticText ''\n\t\t\t\t[128] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dcgan/  $ python3 dcgan.py'\n\t\t\t[35] button ''\n\t\t\tparagraph ''\n\t\t\t\t[129] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\theading 'DiscoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Learning to Discover Cross-Domain Relations with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity.'\n\t\t\tparagraph ''\n\t\t\t\t[130] link '[Paper]', url='https://arxiv.org/abs/1703.05192'\n\t\t\t\tStaticText ''\n\t\t\t\t[131] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py'\n\t\t\tparagraph ''\n\t\t\t\t[132] link '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/discogan/  $ python3 discogan.py --dataset_name edges2shoes'\n\t\t\t[36] button ''\n\t\t\tparagraph ''\n\t\t\t\t[133] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real image from domain A (2) Translated image from domain A (3) Reconstructed image from domain A (4) Real image from domain B (5) Translated image from domain B (6) Reconstructed image from domain B'\n\t\t\theading 'DRAGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'On Convergence and Stability of GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.'\n\t\t\tparagraph ''\n\t\t\t\t[134] link '[Paper]', url='https://arxiv.org/abs/1705.07215'\n\t\t\t\tStaticText ''\n\t\t\t\t[135] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dragan/  $ python3 dragan.py'\n\t\t\t[37] button ''\n\t\t\theading 'DualGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'DualGAN: Unsupervised Dual Learning for Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Zili Yi, Hao Zhang, Ping Tan, Minglun Gong'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data.'\n\t\t\tparagraph ''\n\t\t\t\t[136] link '[Paper]', url='https://arxiv.org/abs/1704.02510'\n\t\t\t\tStaticText ''\n\t\t\t\t[137] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/dualgan/  $ python3 dualgan.py --dataset_name facades'\n\t\t\t[38] button ''\n\t\t\theading 'Energy-Based GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Energy-based Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Junbo Zhao, Michael Mathieu, Yann LeCun'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.'\n\t\t\tparagraph ''\n\t\t\t\t[138] link '[Paper]', url='https://arxiv.org/abs/1609.03126'\n\t\t\t\tStaticText ''\n\t\t\t\t[139] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ebgan/  $ python3 ebgan.py'\n\t\t\t[39] button ''\n\t\t\theading 'Enhanced Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at'\n\t\t\t\t[140] link 'this https URL', url='https://github.com/xinntao/ESRGAN'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[141] link '[Paper]', url='https://arxiv.org/abs/1809.00219'\n\t\t\t\tStaticText ''\n\t\t\t\t[142] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/esrgan/  <follow steps at the top of esrgan.py>  $ python3 esrgan.py'\n\t\t\t[40] button ''\n\t\t\tparagraph ''\n\t\t\t\t[143] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | ESRGAN'\n\t\t\theading 'GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.'\n\t\t\tparagraph ''\n\t\t\t\t[144] link '[Paper]', url='https://arxiv.org/abs/1406.2661'\n\t\t\t\tStaticText ''\n\t\t\t\t[145] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/gan/  $ python3 gan.py'\n\t\t\t[41] button ''\n\t\t\tparagraph ''\n\t\t\t\t[146] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\theading 'InfoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.'\n\t\t\tparagraph ''\n\t\t\t\t[147] link '[Paper]', url='https://arxiv.org/abs/1606.03657'\n\t\t\t\tStaticText ''\n\t\t\t\t[148] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/infogan/  $ python3 infogan.py'\n\t\t\t[42] button ''\n\t\t\tparagraph ''\n\t\t\t\t[149] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying categorical latent variable by column.'\n\t\t\tparagraph ''\n\t\t\t\t[150] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying continuous latent variable by row.'\n\t\t\theading 'Least Squares GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Least Squares Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson œá2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.'\n\t\t\tparagraph ''\n\t\t\t\t[151] link '[Paper]', url='https://arxiv.org/abs/1611.04076'\n\t\t\t\tStaticText ''\n\t\t\t\t[152] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/lsgan/  $ python3 lsgan.py'\n\t\t\t[43] button ''\n\t\t\theading 'MUNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Multimodal Unsupervised Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at'\n\t\t\t\t[153] link 'this https URL', url='https://github.com/nvlabs/MUNIT'\n\t\t\tparagraph ''\n\t\t\t\t[154] link '[Paper]', url='https://arxiv.org/abs/1804.04732'\n\t\t\t\tStaticText ''\n\t\t\t\t[155] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/munit/  $ python3 munit.py --dataset_name edges2shoes'\n\t\t\t[44] button ''\n\t\t\tparagraph ''\n\t\t\t\t[156] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Results by varying the style code.'\n\t\t\theading 'Pix2Pix'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation with Conditional Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.'\n\t\t\tparagraph ''\n\t\t\t\t[157] link '[Paper]', url='https://arxiv.org/abs/1611.07004'\n\t\t\t\tStaticText ''\n\t\t\t\t[158] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py'\n\t\t\tparagraph ''\n\t\t\t\t[159] link '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/pix2pix/  $ python3 pix2pix.py --dataset_name facades'\n\t\t\t[45] button ''\n\t\t\tparagraph ''\n\t\t\t\t[160] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) The condition for the generator (2) Generated image based of condition (3) The true corresponding image to the condition'\n\t\t\theading 'PixelDA'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training.'\n\t\t\tparagraph ''\n\t\t\t\t[161] link '[Paper]', url='https://arxiv.org/abs/1612.05424'\n\t\t\t\tStaticText ''\n\t\t\t\t[162] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py'\n\t\t\theading 'MNIST to MNIST-M Classification'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy.'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/pixelda/  $ python3 pixelda.py'\n\t\t\t[46] button ''\n\t\t\ttable ''\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcolumnheader 'Method'\n\t\t\t\t\t\tcolumnheader 'Accuracy'\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'Naive'\n\t\t\t\t\t\tcell '55%'\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'PixelDA'\n\t\t\t\t\t\tcell '95%'\n\t\t\tparagraph ''\n\t\t\t\t[163] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real images from MNIST (2) Translated images from MNIST to MNIST-M (3) Examples of images from MNIST-M'\n\t\t\theading 'Relativistic GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'The relativistic discriminator: a key element missing from standard GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alexia Jolicoeur-Martineau'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.'\n\t\t\tparagraph ''\n\t\t\t\t[164] link '[Paper]', url='https://arxiv.org/abs/1807.00734'\n\t\t\t\tStaticText ''\n\t\t\t\t[165] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/relativistic_gan/  $ python3 relativistic_gan.py                 # Relativistic Standard GAN  $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN'\n\t\t\t[47] button ''\n\t\t\theading 'Semi-Supervised GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN.'\n\t\t\tparagraph ''\n\t\t\t\t[166] link '[Paper]', url='https://arxiv.org/abs/1606.01583'\n\t\t\t\tStaticText ''\n\t\t\t\t[167] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/sgan/  $ python3 sgan.py'\n\t\t\t[48] button ''\n\t\t\theading 'Softmax GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Softmax GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Min Lin'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training.'\n\t\t\tparagraph ''\n\t\t\t\t[168] link '[Paper]', url='https://arxiv.org/abs/1704.06191'\n\t\t\t\tStaticText ''\n\t\t\t\t[169] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/softmax_gan/  $ python3 softmax_gan.py'\n\t\t\t[49] button ''\n\t\t\theading 'StarGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText \"Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.\"\n\t\t\tparagraph ''\n\t\t\t\t[170] link '[Paper]', url='https://arxiv.org/abs/1711.09020'\n\t\t\t\tStaticText ''\n\t\t\t\t[171] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/stargan/  <follow steps at the top of stargan.py>  $ python3 stargan.py'\n\t\t\t[50] button ''\n\t\t\tparagraph ''\n\t\t\t\t[172] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged'\n\t\t\theading 'Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.'\n\t\t\tparagraph ''\n\t\t\t\t[173] link '[Paper]', url='https://arxiv.org/abs/1609.04802'\n\t\t\t\tStaticText ''\n\t\t\t\t[174] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py'\n\t\t\tparagraph ''\n\t\t\t\t[175] link '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/srgan/  <follow steps at the top of srgan.py>  $ python3 srgan.py'\n\t\t\t[51] button ''\n\t\t\tparagraph ''\n\t\t\t\t[176] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | SRGAN'\n\t\t\theading 'UNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Image-to-Image Translation Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Thomas Breuel, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this'\n\t\t\t\t[177] link 'https URL', url='https://github.com/mingyuliutw/unit'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[178] link '[Paper]', url='https://arxiv.org/abs/1703.00848'\n\t\t\t\tStaticText ''\n\t\t\t\t[179] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh apple2orange  $ cd implementations/unit/  $ python3 unit.py --dataset_name apple2orange'\n\t\t\t[52] button ''\n\t\t\theading 'Wasserstein GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Martin Arjovsky, Soumith Chintala, L√©on Bottou'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.'\n\t\t\tparagraph ''\n\t\t\t\t[180] link '[Paper]', url='https://arxiv.org/abs/1701.07875'\n\t\t\t\tStaticText ''\n\t\t\t\t[181] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan/  $ python3 wgan.py'\n\t\t\t[53] button ''\n\t\t\theading 'Wasserstein GAN GP'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Improved Training of Wasserstein GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.'\n\t\t\tparagraph ''\n\t\t\t\t[182] link '[Paper]', url='https://arxiv.org/abs/1704.00028'\n\t\t\t\tStaticText ''\n\t\t\t\t[183] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_gp/  $ python3 wgan_gp.py'\n\t\t\t[54] button ''\n\t\t\tparagraph ''\n\t\t\t\t[184] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\theading 'Wasserstein GAN DIV'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein Divergence for GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods.'\n\t\t\tparagraph ''\n\t\t\t\t[185] link '[Paper]', url='https://arxiv.org/abs/1712.01026'\n\t\t\t\tStaticText ''\n\t\t\t\t[186] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_div/  $ python3 wgan_div.py'\n\t\t\t[55] button ''\n\t\t\tparagraph ''\n\t\t\t\t[187] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'",
    "action": {
      "code": "stop('git clone ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git')",
      "thought": "The requirement is to provide the clone command using SSH for the best GAN Python implementation. The page shows the correct SSH URL, and the command format is `git clone <URL>`. No further exploration is necessary.",
      "type": "stop",
      "args": {
        "text": "git clone ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git"
      },
      "selected_element": {}
    },
    "action_error": "",
    "obs_description": "The current repository page for **eriklindernoren/PyTorch-GAN** is open with the Clone button (ID 18) expanded. In the ‚ÄúClone with SSH‚Äù section the textbox contains the SSH clone URL:\n\n```\nssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git\n```\n\nThis is the exact SSH URL needed to clone the repository.",
    "http_requests": []
  },
  {
    "open_pages_titles": [
      "Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab"
    ],
    "open_pages_urls": [
      "http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN"
    ],
    "active_page_index": 0,
    "axtree_txt": "RootWebArea 'Erik Linder-Nor√©n / PyTorch-GAN ¬∑ GitLab', focused, url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tbanner ''\n\t\t[1] link 'Skip to content', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#content-body'\n\t\tStaticText 'GitLab'\n\t\t[2] link 'Dashboard', url='http://127.0.0.1:8023/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[56] button '', hasPopup='menu', expanded=False\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[57] textbox 'Search GitLab'\n\t\t\t\tStaticText '/'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[58] link 'Create new...', url='http://127.0.0.1:8023/projects/new'\n\t\t\tlistitem ''\n\t\t\t\t[59] link 'Issues', url='http://127.0.0.1:8023/dashboard/issues?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[60] link 'Merge requests', url='http://127.0.0.1:8023/dashboard/merge_requests?assignee_username=byteblaze'\n\t\t\tlistitem ''\n\t\t\t\t[61] link 'To-Do List', url='http://127.0.0.1:8023/dashboard/todos'\n\t\t\t\t\tStaticText '5'\n\t\t\tlistitem ''\n\t\t\t\t[62] link 'Help', url='http://127.0.0.1:8023/help'\n\t\t\tlistitem ''\n\t\t\t\t[63] link 'Byte Blaze', url='http://127.0.0.1:8023/byteblaze'\n\t\t\t\t\timage 'Byte Blaze', url='https://www.gravatar.com/avatar/99a4297c867eada2606b9b6973f081f9?s=48&d=identicon'\n\tcomplementary 'Project navigation'\n\t\tlist ''\n\t\t\tlistitem 'PyTorch-GAN'\n\t\t\t\t[64] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\t\t\tlistitem ''\n\t\t\t\t[65] link 'Project information', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/activity'\n\t\t\tlistitem ''\n\t\t\t\t[66] link 'Repository', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master'\n\t\t\tlistitem ''\n\t\t\t\t[67] link 'Issues', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/issues'\n\t\t\t\t\tStaticText '102'\n\t\t\tlistitem ''\n\t\t\t\t[68] link 'Merge requests', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/merge_requests'\n\t\t\t\t\tStaticText '24'\n\t\t\tlistitem ''\n\t\t\t\t[69] link 'CI/CD', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/pipelines'\n\t\t\tlistitem ''\n\t\t\t\t[70] link 'Deployments', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/environments'\n\t\t\tlistitem ''\n\t\t\t\t[71] link 'Packages and registries', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/packages'\n\t\t\tlistitem ''\n\t\t\t\t[72] link 'Monitor', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/incidents'\n\t\t\tlistitem ''\n\t\t\t\t[73] link 'Analytics', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/value_stream_analytics'\n\t\t\tlistitem ''\n\t\t\t\t[74] link 'Wiki', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/wikis/home'\n\t\t\tlistitem ''\n\t\t\t\t[75] link 'Snippets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/snippets'\n\t\t[3] button 'Collapse sidebar'\n\talert '', live='assertive', atomic, relevant='additions text'\n\t\t[4] button 'Dismiss'\n\t\talert '', live='assertive', atomic, relevant='additions text'\n\t\t\tStaticText \"You can't push or pull repositories using SSH until you add an SSH key to your profile.\"\n\t\t\t[19] link 'Add SSH key', url='http://127.0.0.1:8023/-/profile/keys'\n\t\t\t[20] button \"Don't show again\"\n\tnavigation 'Breadcrumbs'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[76] link 'Erik Linder-Nor√©n', url='http://127.0.0.1:8023/eriklindernoren'\n\t\t\tlistitem ''\n\t\t\t\t[77] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN'\n\tmain ''\n\t\tStaticText 'P'\n\t\theading 'PyTorch-GAN'\n\t\tStaticText 'Project ID: 86'\n\t\t[5] button 'Copy project ID', live='polite', relevant='additions text'\n\t\t[6] link 'Request Access', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/project_members/request_access'\n\t\t[7] button '', hasPopup='menu', expanded=False\n\t\t[8] button 'Star'\n\t\t[9] link '45', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/starrers'\n\t\t[10] link 'Fork', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks/new'\n\t\t[11] link '0', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/forks'\n\t\tnavigation ''\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[188] link '193 Commits', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commits/master'\n\t\t\t\t\t\t[197] strong ''\n\t\t\t\t\t\t\tStaticText '193'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[189] link '25 Branches', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/branches'\n\t\t\t\t\t\t[198] strong ''\n\t\t\t\t\t\t\tStaticText '25'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[190] link '0 Tags', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tags'\n\t\t\t\t\t\t[199] strong ''\n\t\t\t\t\t\t\tStaticText '0'\n\t\t\t\tlistitem ''\n\t\t\t\t\t[191] strong ''\n\t\t\t\t\t\tStaticText '184.7 MB'\n\t\t\t\t\tStaticText 'Project Storage'\n\t\tparagraph ''\n\t\t\tStaticText 'PyTorch implementations of Generative Adversarial Networks.'\n\t\timage 'user avatar', url='https://www.gravatar.com/avatar/8d7c025d033d490fae9de8c637722ba4?s=80&d=identicon'\n\t\t[12] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\tStaticText 'Erik Linder-Nor√©n authored'\n\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\tStaticText '4 years ago'\n\t\t[13] button 'Unverified'\n\t\tgroup ''\n\t\t\tStaticText '36d3c77e'\n\t\t\t[21] button 'Copy commit SHA', live='polite', relevant='additions text'\n\t\t[14] button 'master', hasPopup='menu', expanded=False\n\t\tnavigation 'Files breadcrumb'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\t[192] link 'PyTorch-GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/'\n\t\t\t\tlistitem ''\n\t\t\t\t\tStaticText '/'\n\t\t\t\t\t[193] button 'Add to tree', hasPopup='menu', expanded=False\n\t\t[15] link 'Find file', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/find_file/master'\n\t\t[16] link 'Web IDE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#modal-confirm-fork-webide'\n\t\t[17] button 'Download'\n\t\t\tStaticText 'Select Archive Format'\n\t\t[18] link 'Clone', focused, expanded=True, url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[78] LabelText ''\n\t\t\t\t\tStaticText 'Clone with SSH'\n\t\t\t\t[79] textbox 'Repository clone URL' value='ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t\tStaticText 'ssh://git@127.0.0.1:2222/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t[80] button 'Copy URL', live='polite', relevant='additions text'\n\t\t\tlistitem ''\n\t\t\t\t[81] LabelText ''\n\t\t\t\t\tStaticText 'Clone with HTTP'\n\t\t\t\t[82] textbox 'Repository clone URL' value='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t\tStaticText 'http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN.git'\n\t\t\t\t[83] button 'Copy URL', live='polite', relevant='additions text'\n\t\t\tlistitem ''\n\t\t\tlistitem ''\n\t\t\t\t[84] LabelText ''\n\t\t\t\t\tStaticText 'Open in your IDE'\n\t\t\t\t[85] link 'Visual Studio Code (SSH)', url='vscode://vscode.git/clone?url=ssh%3A%2F%2Fgit%40127.0.0.1%3A2222%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[86] link 'Visual Studio Code (HTTPS)', url='vscode://vscode.git/clone?url=http%3A%2F%2F127.0.0.1%3A8023%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[87] link 'IntelliJ IDEA (SSH)', url='jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=ssh%3A%2F%2Fgit%40127.0.0.1%3A2222%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\t\t\t[88] link 'IntelliJ IDEA (HTTPS)', url='jetbrains://idea/checkout/git?idea.required.plugins.id=Git4Idea&checkout.repo=http%3A%2F%2F127.0.0.1%3A8023%2Feriklindernoren%2FPyTorch-GAN.git'\n\t\tlist ''\n\t\t\tlistitem ''\n\t\t\t\t[89] link 'README', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\tlistitem ''\n\t\t\t\t[90] link 'MIT License', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\ttable 'Files, directories, and submodules in the path / for commit reference master', live='polite', relevant='additions text'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcolumnheader 'Name'\n\t\t\t\t\tcolumnheader 'Last commit'\n\t\t\t\t\tcolumnheader 'Last update'\n\t\t\trowgroup ''\n\t\t\t\trow ''\n\t\t\t\t\tcell 'assets'\n\t\t\t\t\t\t[200] link 'assets', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/assets'\n\t\t\t\t\tcell 'adds clustergan gif'\n\t\t\t\t\t\t[201] link 'adds clustergan gif', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/23a2b9f4514cc997a8689e5e19fbddf7adc539f6'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:52pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'data'\n\t\t\t\t\t\t[202] link 'data', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/data'\n\t\t\t\t\tcell 'Figures'\n\t\t\t\t\t\t[203] link 'Figures', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/df342dd3ecd5270a8810bdaae30c1c6571ac31bc'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 23, 2018 8:13pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'implementations'\n\t\t\t\t\t\t[204] link 'implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/tree/master/implementations'\n\t\t\t\t\tcell 'Adds single clustergan script'\n\t\t\t\t\t\t[205] link 'Adds single clustergan script', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/5f84be03dec16e032d170dafd1689ca948218e88'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Jun 17, 2019 10:43am GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell '.gitignore'\n\t\t\t\t\t\t[206] link '.gitignore', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/.gitignore'\n\t\t\t\t\tcell 'MNIST normalization. Black refactoring.'\n\t\t\t\t\t\t[207] link 'MNIST normalization. Black refactoring.', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/c5d6be170013db8975d96806084df573d87e5d26'\n\t\t\t\t\tcell '6 years ago'\n\t\t\t\t\t\ttime 'Mar 28, 2019 8:55pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '6 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'LICENSE'\n\t\t\t\t\t\t[208] link 'LICENSE', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/LICENSE'\n\t\t\t\t\tcell 'Initial commit'\n\t\t\t\t\t\t[209] link 'Initial commit', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/a18bcc2695e95e10420570913816317b1f233438'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'Apr 21, 2018 7:06pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'README.md'\n\t\t\t\t\t\t[210] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t\tcell 'Update README.md'\n\t\t\t\t\t\t[211] link 'Update README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/36d3c77e5ff20ebe0aeefd322326a134a279b93e'\n\t\t\t\t\tcell '4 years ago'\n\t\t\t\t\t\ttime 'Jan 6, 2021 10:32pm GMT+0600'\n\t\t\t\t\t\t\tStaticText '4 years ago'\n\t\t\t\trow ''\n\t\t\t\t\tcell 'requirements.txt'\n\t\t\t\t\t\t[212] link 'requirements.txt', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/requirements.txt'\n\t\t\t\t\tcell 'Added PyTorch 0.4.0 to requirements'\n\t\t\t\t\t\t[213] link 'Added PyTorch 0.4.0 to requirements', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/commit/8400a6e4ab0eb1a69f641bc568ce56049a2112eb'\n\t\t\t\t\tcell '7 years ago'\n\t\t\t\t\t\ttime 'May 25, 2018 4:49am GMT+0600'\n\t\t\t\t\t\t\tStaticText '7 years ago'\n\t\tarticle ''\n\t\t\t[22] link 'README.md', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/README.md'\n\t\t\t\t[91] strong ''\n\t\t\t\t\tStaticText 'README.md'\n\t\t\tparagraph ''\n\t\t\t\t[92] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/logo.png'\n\t\t\tparagraph ''\n\t\t\t\t[93] strong ''\n\t\t\t\t\tStaticText 'This repository has gone stale as I unfortunately do not have the time to maintain it anymore. If you would like to continue the development of it as a collaborator send me an email at'\n\t\t\t\t\t[194] link 'eriklindernoren@gmail.com', url='mailto:eriklindernoren@gmail.com'\n\t\t\t\t\tStaticText '.'\n\t\t\theading 'PyTorch-GAN'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collection of PyTorch implementations of Generative Adversarial Network varieties presented in research papers. Model architectures will not always mirror the ones proposed in the papers, but I have chosen to focus on getting the core ideas covered instead of getting every layer configuration right. Contributions and suggestions of GANs to implement are very welcomed.'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'See also: '\n\t\t\t\t[94] link 'Keras-GAN', url='https://github.com/eriklindernoren/Keras-GAN'\n\t\t\theading 'Table of Contents'\n\t\t\tlist ''\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[195] link 'Installation', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#installation'\n\t\t\t\tlistitem ''\n\t\t\t\t\tListMarker '‚Ä¢'\n\t\t\t\t\t[196] link 'Implementations', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#implementations'\n\t\t\t\t\tlist ''\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[214] link 'Auxiliary Classifier GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#auxiliary-classifier-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[215] link 'Adversarial Autoencoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#adversarial-autoencoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[216] link 'BEGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#began'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[217] link 'BicycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#bicyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[218] link 'Boundary-Seeking GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#boundary-seeking-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[219] link 'Cluster GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cluster-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[220] link 'Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[221] link 'Context-Conditional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-conditional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[222] link 'Context Encoder', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#context-encoder'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[223] link 'Coupled GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#coupled-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[224] link 'CycleGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#cyclegan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[225] link 'Deep Convolutional GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#deep-convolutional-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[226] link 'DiscoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#discogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[227] link 'DRAGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dragan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[228] link 'DualGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#dualgan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[229] link 'Energy-Based GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#energy-based-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[230] link 'Enhanced Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#enhanced-super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[231] link 'GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[232] link 'InfoGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#infogan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[233] link 'Least Squares GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#least-squares-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[234] link 'MUNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#munit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[235] link 'Pix2Pix', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pix2pix'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[236] link 'PixelDA', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#pixelda'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[237] link 'Relativistic GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#relativistic-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[238] link 'Semi-Supervised GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#semi-supervised-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[239] link 'Softmax GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#softmax-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[240] link 'StarGAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#stargan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[241] link 'Super-Resolution GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#super-resolution-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[242] link 'UNIT', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#unit'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[243] link 'Wasserstein GAN', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[244] link 'Wasserstein GAN GP', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-gp'\n\t\t\t\t\t\tlistitem ''\n\t\t\t\t\t\t\tListMarker '‚ó¶'\n\t\t\t\t\t\t\t[245] link 'Wasserstein GAN DIV', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN#wasserstein-gan-div'\n\t\t\theading 'Installation'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ git clone https://github.com/eriklindernoren/PyTorch-GAN  $ cd PyTorch-GAN/  $ sudo pip3 install -r requirements.txt'\n\t\t\t[23] button ''\n\t\t\theading 'Implementations'\n\t\t\theading 'Auxiliary Classifier GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Auxiliary Classifier Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena, Christopher Olah, Jonathon Shlens'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Synthesizing high resolution photorealistic images has been a long-standing challenge in machine learning. In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128x128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128x128 samples are more than twice as discriminable as artificially resized 32x32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.'\n\t\t\tparagraph ''\n\t\t\t\t[95] link '[Paper]', url='https://arxiv.org/abs/1610.09585'\n\t\t\t\tStaticText ''\n\t\t\t\t[96] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/acgan/acgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/acgan/  $ python3 acgan.py'\n\t\t\t[24] button ''\n\t\t\tparagraph ''\n\t\t\t\t[97] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/acgan.gif'\n\t\t\theading 'Adversarial Autoencoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Adversarial Autoencoder'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'n this paper, we propose the \"adversarial autoencoder\" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.'\n\t\t\tparagraph ''\n\t\t\t\t[98] link '[Paper]', url='https://arxiv.org/abs/1511.05644'\n\t\t\t\tStaticText ''\n\t\t\t\t[99] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/aae/aae.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/aae/  $ python3 aae.py'\n\t\t\t[25] button ''\n\t\t\theading 'BEGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'BEGAN: Boundary Equilibrium Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'David Berthelot, Thomas Schumm, Luke Metz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure.'\n\t\t\tparagraph ''\n\t\t\t\t[100] link '[Paper]', url='https://arxiv.org/abs/1703.10717'\n\t\t\t\tStaticText ''\n\t\t\t\t[101] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/began/began.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/began/  $ python3 began.py'\n\t\t\t[26] button ''\n\t\t\theading 'BicycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Toward Multimodal Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a \\\\\\\\emph{distribution} of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.'\n\t\t\tparagraph ''\n\t\t\t\t[102] link '[Paper]', url='https://arxiv.org/abs/1711.11586'\n\t\t\t\tStaticText ''\n\t\t\t\t[103] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bicyclegan/bicyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[104] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan_architecture.jpg'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/bicyclegan/  $ python3 bicyclegan.py'\n\t\t\t[27] button ''\n\t\t\tparagraph ''\n\t\t\t\t[105] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/bicyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Various style translations by varying the latent code.'\n\t\t\theading 'Boundary-Seeking GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Boundary-Seeking Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'R Devon Hjelm, Athul Paul Jacob, Tong Che, Adam Trischler, Kyunghyun Cho, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training, and we demonstrate this on Celeba, Large-scale Scene Understanding (LSUN) bedrooms, and Imagenet without conditioning.'\n\t\t\tparagraph ''\n\t\t\t\t[106] link '[Paper]', url='https://arxiv.org/abs/1702.08431'\n\t\t\t\tStaticText ''\n\t\t\t\t[107] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/bgan/bgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/bgan/  $ python3 bgan.py'\n\t\t\t[28] button ''\n\t\t\theading 'Cluster GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ClusterGAN: Latent Space Clustering in Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, Sreeram Kannan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial networks (GANs) have obtained remarkable success in many unsupervised learning tasks and unarguably, clustering is an important unsupervised learning problem. While one can potentially exploit the latent-space back-projection in GANs to cluster, we demonstrate that the cluster structure is not retained in the GAN latent space. In this paper, we propose ClusterGAN as a new mechanism for clustering using GANs. By sampling latent variables from a mixture of one-hot encoded variables and continuous latent variables, coupled with an inverse network (which projects the data to the latent space) trained jointly with a clustering specific loss, we are able to achieve clustering in the latent space. Our results show a remarkable phenomenon that GANs can preserve latent space interpolation across categories, even though the discriminator is never exposed to such vectors. We compare our results with various clustering baselines and demonstrate superior performance on both synthetic and real datasets.'\n\t\t\tparagraph ''\n\t\t\t\t[108] link '[Paper]', url='https://arxiv.org/abs/1809.03627'\n\t\t\t\tStaticText ''\n\t\t\t\t[109] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cluster_gan/clustergan.py'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Code based on a full PyTorch'\n\t\t\t\t[110] link '[implementation]', url='https://github.com/zhampel/clusterGAN'\n\t\t\t\tStaticText '.'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cluster_gan/  $ python3 clustergan.py'\n\t\t\t[29] button ''\n\t\t\tparagraph ''\n\t\t\t\t[111] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cluster_gan.gif'\n\t\t\theading 'Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Conditional Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Mehdi Mirza, Simon Osindero'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.'\n\t\t\tparagraph ''\n\t\t\t\t[112] link '[Paper]', url='https://arxiv.org/abs/1411.1784'\n\t\t\t\tStaticText ''\n\t\t\t\t[113] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cgan/cgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cgan/  $ python3 cgan.py'\n\t\t\t[30] button ''\n\t\t\tparagraph ''\n\t\t\t\t[114] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cgan.gif'\n\t\t\theading 'Context-Conditional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Emily Denton, Sam Gross, Rob Fergus'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a simple semi-supervised learning approach for images based on in-painting using an adversarial loss. Images with random patches removed are presented to a generator whose task is to fill in the hole, based on the surrounding pixels. The in-painted images are then presented to a discriminator network that judges if they are real (unaltered training images) or not. This task acts as a regularizer for standard supervised training of the discriminator. Using our approach we are able to directly train large VGG-style networks in a semi-supervised fashion. We evaluate on STL-10 and PASCAL datasets, where our approach obtains performance comparable or superior to existing methods.'\n\t\t\tparagraph ''\n\t\t\t\t[115] link '[Paper]', url='https://arxiv.org/abs/1611.06430'\n\t\t\t\tStaticText ''\n\t\t\t\t[116] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ccgan/ccgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ccgan/  $ python3 ccgan.py'\n\t\t\t[31] button ''\n\t\t\theading 'Context Encoder'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Context Encoders: Feature Learning by Inpainting'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.'\n\t\t\tparagraph ''\n\t\t\t\t[117] link '[Paper]', url='https://arxiv.org/abs/1604.07379'\n\t\t\t\tStaticText ''\n\t\t\t\t[118] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/context_encoder/context_encoder.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/context_encoder/  <follow steps at the top of context_encoder.py>  $ python3 context_encoder.py'\n\t\t\t[32] button ''\n\t\t\tparagraph ''\n\t\t\t\t[119] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/context_encoder.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows: Masked | Inpainted | Original | Masked | Inpainted | Original'\n\t\t\theading 'Coupled GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Coupled Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Oncel Tuzel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation.'\n\t\t\tparagraph ''\n\t\t\t\t[120] link '[Paper]', url='https://arxiv.org/abs/1606.07536'\n\t\t\t\tStaticText ''\n\t\t\t\t[121] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cogan/cogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/cogan/  $ python3 cogan.py'\n\t\t\t[33] button ''\n\t\t\tparagraph ''\n\t\t\t\t[122] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generated MNIST and MNIST-M images'\n\t\t\theading 'CycleGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G:X‚ÜíY such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F:Y‚ÜíX and introduce a cycle consistency loss to push F(G(X))‚âàX (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.'\n\t\t\tparagraph ''\n\t\t\t\t[123] link '[Paper]', url='https://arxiv.org/abs/1703.10593'\n\t\t\t\tStaticText ''\n\t\t\t\t[124] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/cyclegan/cyclegan.py'\n\t\t\tparagraph ''\n\t\t\t\t[125] link '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/cyclegan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh monet2photo  $ cd ../implementations/cyclegan/  $ python3 cyclegan.py --dataset_name monet2photo'\n\t\t\t[34] button ''\n\t\t\tparagraph ''\n\t\t\t\t[126] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/cyclegan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Monet to photo translations.'\n\t\t\theading 'Deep Convolutional GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Deep Convolutional Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alec Radford, Luke Metz, Soumith Chintala'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.'\n\t\t\tparagraph ''\n\t\t\t\t[127] link '[Paper]', url='https://arxiv.org/abs/1511.06434'\n\t\t\t\tStaticText ''\n\t\t\t\t[128] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dcgan/dcgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dcgan/  $ python3 dcgan.py'\n\t\t\t[35] button ''\n\t\t\tparagraph ''\n\t\t\t\t[129] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/dcgan.gif'\n\t\t\theading 'DiscoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Learning to Discover Cross-Domain Relations with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity.'\n\t\t\tparagraph ''\n\t\t\t\t[130] link '[Paper]', url='https://arxiv.org/abs/1703.05192'\n\t\t\t\tStaticText ''\n\t\t\t\t[131] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/discogan/discogan.py'\n\t\t\tparagraph ''\n\t\t\t\t[132] link '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/discogan_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/discogan/  $ python3 discogan.py --dataset_name edges2shoes'\n\t\t\t[36] button ''\n\t\t\tparagraph ''\n\t\t\t\t[133] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/discogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real image from domain A (2) Translated image from domain A (3) Reconstructed image from domain A (4) Real image from domain B (5) Translated image from domain B (6) Reconstructed image from domain B'\n\t\t\theading 'DRAGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'On Convergence and Stability of GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.'\n\t\t\tparagraph ''\n\t\t\t\t[134] link '[Paper]', url='https://arxiv.org/abs/1705.07215'\n\t\t\t\tStaticText ''\n\t\t\t\t[135] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dragan/dragan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/dragan/  $ python3 dragan.py'\n\t\t\t[37] button ''\n\t\t\theading 'DualGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'DualGAN: Unsupervised Dual Learning for Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Zili Yi, Hao Zhang, Ping Tan, Minglun Gong'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation, we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V, while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data.'\n\t\t\tparagraph ''\n\t\t\t\t[136] link '[Paper]', url='https://arxiv.org/abs/1704.02510'\n\t\t\t\tStaticText ''\n\t\t\t\t[137] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/dualgan/dualgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/dualgan/  $ python3 dualgan.py --dataset_name facades'\n\t\t\t[38] button ''\n\t\t\theading 'Energy-Based GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Energy-based Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Junbo Zhao, Michael Mathieu, Yann LeCun'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce the \"Energy-based Generative Adversarial Network\" model (EBGAN) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. Similar to the probabilistic GANs, a generator is seen as being trained to produce contrastive samples with minimal energies, while the discriminator is trained to assign high energies to these generated samples. Viewing the discriminator as an energy function allows to use a wide variety of architectures and loss functionals in addition to the usual binary classifier with logistic output. Among them, we show one instantiation of EBGAN framework as using an auto-encoder architecture, with the energy being the reconstruction error, in place of the discriminator. We show that this form of EBGAN exhibits more stable behavior than regular GANs during training. We also show that a single-scale architecture can be trained to generate high-resolution images.'\n\t\t\tparagraph ''\n\t\t\t\t[138] link '[Paper]', url='https://arxiv.org/abs/1609.03126'\n\t\t\t\tStaticText ''\n\t\t\t\t[139] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/ebgan/ebgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/ebgan/  $ python3 ebgan.py'\n\t\t\t[39] button ''\n\t\t\theading 'Enhanced Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Chen Change Loy, Yu Qiao, Xiaoou Tang'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at'\n\t\t\t\t[140] link 'this https URL', url='https://github.com/xinntao/ESRGAN'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[141] link '[Paper]', url='https://arxiv.org/abs/1809.00219'\n\t\t\t\tStaticText ''\n\t\t\t\t[142] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/esrgan/esrgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/esrgan/  <follow steps at the top of esrgan.py>  $ python3 esrgan.py'\n\t\t\t[40] button ''\n\t\t\tparagraph ''\n\t\t\t\t[143] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/enhanced_superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | ESRGAN'\n\t\t\theading 'GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.'\n\t\t\tparagraph ''\n\t\t\t\t[144] link '[Paper]', url='https://arxiv.org/abs/1406.2661'\n\t\t\t\tStaticText ''\n\t\t\t\t[145] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/gan/gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/gan/  $ python3 gan.py'\n\t\t\t[41] button ''\n\t\t\tparagraph ''\n\t\t\t\t[146] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/gan.gif'\n\t\t\theading 'InfoGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.'\n\t\t\tparagraph ''\n\t\t\t\t[147] link '[Paper]', url='https://arxiv.org/abs/1606.03657'\n\t\t\t\tStaticText ''\n\t\t\t\t[148] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/infogan/infogan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/infogan/  $ python3 infogan.py'\n\t\t\t[42] button ''\n\t\t\tparagraph ''\n\t\t\t\t[149] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.gif'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying categorical latent variable by column.'\n\t\t\tparagraph ''\n\t\t\t\t[150] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/infogan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Result of varying continuous latent variable by row.'\n\t\t\theading 'Least Squares GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Least Squares Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xudong Mao, Qing Li, Haoran Xie, Raymond Y.K. Lau, Zhen Wang, Stephen Paul Smolley'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson œá2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.'\n\t\t\tparagraph ''\n\t\t\t\t[151] link '[Paper]', url='https://arxiv.org/abs/1611.04076'\n\t\t\t\tStaticText ''\n\t\t\t\t[152] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/lsgan/lsgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/lsgan/  $ python3 lsgan.py'\n\t\t\t[43] button ''\n\t\t\theading 'MUNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Multimodal Unsupervised Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation is an important and challenging problem in computer vision. Given an image in the source domain, the goal is to learn the conditional distribution of corresponding images in the target domain, without seeing any pairs of corresponding images. While this conditional distribution is inherently multimodal, existing approaches make an overly simplified assumption, modeling it as a deterministic one-to-one mapping. As a result, they fail to generate diverse outputs from a given source domain image. To address this limitation, we propose a Multimodal Unsupervised Image-to-image Translation (MUNIT) framework. We assume that the image representation can be decomposed into a content code that is domain-invariant, and a style code that captures domain-specific properties. To translate an image to another domain, we recombine its content code with a random style code sampled from the style space of the target domain. We analyze the proposed framework and establish several theoretical results. Extensive experiments with comparisons to the state-of-the-art approaches further demonstrates the advantage of the proposed framework. Moreover, our framework allows users to control the style of translation outputs by providing an example style image. Code and pretrained models are available at'\n\t\t\t\t[153] link 'this https URL', url='https://github.com/nvlabs/MUNIT'\n\t\t\tparagraph ''\n\t\t\t\t[154] link '[Paper]', url='https://arxiv.org/abs/1804.04732'\n\t\t\t\tStaticText ''\n\t\t\t\t[155] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/munit/munit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh edges2shoes  $ cd ../implementations/munit/  $ python3 munit.py --dataset_name edges2shoes'\n\t\t\t[44] button ''\n\t\t\tparagraph ''\n\t\t\t\t[156] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/munit.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Results by varying the style code.'\n\t\t\theading 'Pix2Pix'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unpaired Image-to-Image Translation with Conditional Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.'\n\t\t\tparagraph ''\n\t\t\t\t[157] link '[Paper]', url='https://arxiv.org/abs/1611.07004'\n\t\t\t\tStaticText ''\n\t\t\t\t[158] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pix2pix/pix2pix.py'\n\t\t\tparagraph ''\n\t\t\t\t[159] link '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/pix2pix_architecture.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_pix2pix_dataset.sh facades  $ cd ../implementations/pix2pix/  $ python3 pix2pix.py --dataset_name facades'\n\t\t\t[45] button ''\n\t\t\tparagraph ''\n\t\t\t\t[160] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pix2pix.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) The condition for the generator (2) Generated image based of condition (3) The true corresponding image to the condition'\n\t\t\theading 'PixelDA'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training.'\n\t\t\tparagraph ''\n\t\t\t\t[161] link '[Paper]', url='https://arxiv.org/abs/1612.05424'\n\t\t\t\tStaticText ''\n\t\t\t\t[162] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/pixelda/pixelda.py'\n\t\t\theading 'MNIST to MNIST-M Classification'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Trains a classifier on images that have been translated from the source domain (MNIST) to the target domain (MNIST-M) using the annotations of the source domain images. The classification network is trained jointly with the generator network to optimize the generator for both providing a proper domain translation and also for preserving the semantics of the source domain image. The classification network trained on translated images is compared to the naive solution of training a classifier on MNIST and evaluating it on MNIST-M. The naive model manages a 55% classification accuracy on MNIST-M while the one trained during domain adaptation achieves a 95% classification accuracy.'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/pixelda/  $ python3 pixelda.py'\n\t\t\t[46] button ''\n\t\t\ttable ''\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcolumnheader 'Method'\n\t\t\t\t\t\tcolumnheader 'Accuracy'\n\t\t\t\trowgroup ''\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'Naive'\n\t\t\t\t\t\tcell '55%'\n\t\t\t\t\trow ''\n\t\t\t\t\t\tcell 'PixelDA'\n\t\t\t\t\t\tcell '95%'\n\t\t\tparagraph ''\n\t\t\t\t[163] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/pixelda.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Rows from top to bottom: (1) Real images from MNIST (2) Translated images from MNIST to MNIST-M (3) Examples of images from MNIST-M'\n\t\t\theading 'Relativistic GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'The relativistic discriminator: a key element missing from standard GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Alexia Jolicoeur-Martineau'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.'\n\t\t\tparagraph ''\n\t\t\t\t[164] link '[Paper]', url='https://arxiv.org/abs/1807.00734'\n\t\t\t\tStaticText ''\n\t\t\t\t[165] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/relativistic_gan/relativistic_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/relativistic_gan/  $ python3 relativistic_gan.py                 # Relativistic Standard GAN  $ python3 relativistic_gan.py --rel_avg_gan   # Relativistic Average GAN'\n\t\t\t[47] button ''\n\t\t\theading 'Semi-Supervised GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Semi-Supervised Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Augustus Odena'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We extend Generative Adversarial Networks (GANs) to the semi-supervised context by forcing the discriminator network to output class labels. We train a generative model G and a discriminator D on a dataset with inputs belonging to one of N classes. At training time, D is made to predict which of N+1 classes the input belongs to, where an extra class is added to correspond to the outputs of G. We show that this method can be used to create a more data-efficient classifier and that it allows for generating higher quality samples than a regular GAN.'\n\t\t\tparagraph ''\n\t\t\t\t[166] link '[Paper]', url='https://arxiv.org/abs/1606.01583'\n\t\t\t\tStaticText ''\n\t\t\t\t[167] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/sgan/sgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/sgan/  $ python3 sgan.py'\n\t\t\t[48] button ''\n\t\t\theading 'Softmax GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Softmax GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Min Lin'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Softmax GAN is a novel variant of Generative Adversarial Network (GAN). The key idea of Softmax GAN is to replace the classification loss in the original GAN with a softmax cross-entropy loss in the sample space of one single batch. In the adversarial learning of N real training samples and M generated samples, the target of discriminator training is to distribute all the probability mass to the real samples, each with probability 1M, and distribute zero probability to generated data. In the generator training phase, the target is to assign equal probability to all data points in the batch, each with probability 1M+N. While the original GAN is closely related to Noise Contrastive Estimation (NCE), we show that Softmax GAN is the Importance Sampling version of GAN. We futher demonstrate with experiments that this simple change stabilizes GAN training.'\n\t\t\tparagraph ''\n\t\t\t\t[168] link '[Paper]', url='https://arxiv.org/abs/1704.06191'\n\t\t\t\tStaticText ''\n\t\t\t\t[169] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/softmax_gan/softmax_gan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/softmax_gan/  $ python3 softmax_gan.py'\n\t\t\t[49] button ''\n\t\t\theading 'StarGAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText \"Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.\"\n\t\t\tparagraph ''\n\t\t\t\t[170] link '[Paper]', url='https://arxiv.org/abs/1711.09020'\n\t\t\t\tStaticText ''\n\t\t\t\t[171] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/stargan/stargan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/stargan/  <follow steps at the top of stargan.py>  $ python3 stargan.py'\n\t\t\t[50] button ''\n\t\t\tparagraph ''\n\t\t\t\t[172] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/stargan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Original | Black Hair | Blonde Hair | Brown Hair | Gender Flip | Aged'\n\t\t\theading 'Super-Resolution GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.'\n\t\t\tparagraph ''\n\t\t\t\t[173] link '[Paper]', url='https://arxiv.org/abs/1609.04802'\n\t\t\t\tStaticText ''\n\t\t\t\t[174] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/srgan/srgan.py'\n\t\t\tparagraph ''\n\t\t\t\t[175] link '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\t\t\timage '', url='http://eriklindernoren.se/images/superresgan.png'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/srgan/  <follow steps at the top of srgan.py>  $ python3 srgan.py'\n\t\t\t[51] button ''\n\t\t\tparagraph ''\n\t\t\t\t[176] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/superresgan.png'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Nearest Neighbor Upsampling | SRGAN'\n\t\t\theading 'UNIT'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Unsupervised Image-to-Image Translation Networks'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ming-Yu Liu, Thomas Breuel, Jan Kautz'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Unsupervised image-to-image translation aims at learning a joint distribution of images in different domains by using images from the marginal distributions in individual domains. Since there exists an infinite set of joint distributions that can arrive the given marginal distributions, one could infer nothing about the joint distribution from the marginal distributions without additional assumptions. To address the problem, we make a shared-latent space assumption and propose an unsupervised image-to-image translation framework based on Coupled GANs. We compare the proposed framework with competing approaches and present high quality image translation results on various challenging unsupervised image translation tasks, including street scene image translation, animal image translation, and face image translation. We also apply the proposed framework to domain adaptation and achieve state-of-the-art performance on benchmark datasets. Code and additional results are available in this'\n\t\t\t\t[177] link 'https URL', url='https://github.com/mingyuliutw/unit'\n\t\t\t\tStaticText '.'\n\t\t\tparagraph ''\n\t\t\t\t[178] link '[Paper]', url='https://arxiv.org/abs/1703.00848'\n\t\t\t\tStaticText ''\n\t\t\t\t[179] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/unit/unit.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd data/  $ bash download_cyclegan_dataset.sh apple2orange  $ cd implementations/unit/  $ python3 unit.py --dataset_name apple2orange'\n\t\t\t[52] button ''\n\t\t\theading 'Wasserstein GAN'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein GAN'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Martin Arjovsky, Soumith Chintala, L√©on Bottou'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.'\n\t\t\tparagraph ''\n\t\t\t\t[180] link '[Paper]', url='https://arxiv.org/abs/1701.07875'\n\t\t\t\tStaticText ''\n\t\t\t\t[181] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan/wgan.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan/  $ python3 wgan.py'\n\t\t\t[53] button ''\n\t\t\theading 'Wasserstein GAN GP'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Improved Training of Wasserstein GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, Aaron Courville'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.'\n\t\t\tparagraph ''\n\t\t\t\t[182] link '[Paper]', url='https://arxiv.org/abs/1704.00028'\n\t\t\t\tStaticText ''\n\t\t\t\t[183] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_gp/wgan_gp.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_gp/  $ python3 wgan_gp.py'\n\t\t\t[54] button ''\n\t\t\tparagraph ''\n\t\t\t\t[184] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_gp.gif'\n\t\t\theading 'Wasserstein GAN DIV'\n\t\t\tparagraph ''\n\t\t\t\temphasis ''\n\t\t\t\t\tStaticText 'Wasserstein Divergence for GANs'\n\t\t\theading 'Authors'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'Jiqing Wu, Zhiwu Huang, Janine Thoma, Dinesh Acharya, Luc Van Gool'\n\t\t\theading 'Abstract'\n\t\t\tparagraph ''\n\t\t\t\tStaticText 'In many domains of computer vision, generative adversarial networks (GANs) have achieved great success, among which the fam- ily of Wasserstein GANs (WGANs) is considered to be state-of-the-art due to the theoretical contributions and competitive qualitative performance. However, it is very challenging to approximate the k-Lipschitz constraint required by the Wasserstein-1 metric (W-met). In this paper, we propose a novel Wasserstein divergence (W-div), which is a relaxed version of W-met and does not require the k-Lipschitz constraint.As a concrete application, we introduce a Wasserstein divergence objective for GANs (WGAN-div), which can faithfully approximate W-div through optimization. Under various settings, including progressive growing training, we demonstrate the stability of the proposed WGAN-div owing to its theoretical and practical advantages over WGANs. Also, we study the quantitative and visual performance of WGAN-div on standard image synthesis benchmarks, showing the superior performance of WGAN-div compared to the state-of-the-art methods.'\n\t\t\tparagraph ''\n\t\t\t\t[185] link '[Paper]', url='https://arxiv.org/abs/1712.01026'\n\t\t\t\tStaticText ''\n\t\t\t\t[186] link '[Code]', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/blob/master/implementations/wgan_div/wgan_div.py'\n\t\t\theading 'Run Example'\n\t\t\tcode ''\n\t\t\t\tStaticText '$ cd implementations/wgan_div/  $ python3 wgan_div.py'\n\t\t\t[55] button ''\n\t\t\tparagraph ''\n\t\t\t\t[187] link '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'\n\t\t\t\t\timage '', url='http://127.0.0.1:8023/eriklindernoren/PyTorch-GAN/-/raw/master/assets/wgan_div.png'",
    "action": null,
    "action_error": null,
    "obs_description": null,
    "http_requests": []
  }
]